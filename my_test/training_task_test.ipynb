{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test train task\n",
    "## train a model with enough runs\n",
    "## compare results with default MD DFT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import modules\n",
    "from pathlib import Path\n",
    "import torch \n",
    "import logging\n",
    "import shutil\n",
    "from collections import deque\n",
    "from dataclasses import dataclass\n",
    "from random import shuffle, sample\n",
    "from typing import Dict, Any, Optional\n",
    "import json\n",
    "from functools import partial, update_wrapper\n",
    "import numpy as np\n",
    "\n",
    "import ase\n",
    "from ase.db import connect\n",
    "from ase.md.velocitydistribution import MaxwellBoltzmannDistribution\n",
    "from fff.learning.gc.ase import SchnetCalculator\n",
    "from fff.learning.gc.functions import GCSchNetForcefield\n",
    "from fff.learning.gc.models import SchNet, load_pretrained_model\n",
    "from fff.learning.util.messages import TorchMessage\n",
    "from fff.sampling.md import MolecularDynamics\n",
    "from fff.simulation import run_calculator\n",
    "from fff.simulation.utils import read_from_string, write_to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## path and varaibles\n",
    "multisite_path = \"/home/yxx/work/project/colmena/multisite_\"\n",
    "training_set = multisite_path + \"/data/forcefields/starting-model/initial-database.db\"\n",
    "model_path = multisite_path + \"/data/forcefields/starting-model/starting-model\"\n",
    "search_path = training_set\n",
    "out_dir = Path(multisite_path) / f\"my_test/temp\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "starting_model = torch.load(model_path, map_location='cpu')\n",
    "\n",
    "num_epochs = 10\n",
    "huber_deltas = (1, 10)\n",
    "sampler_kwargs = {'device': \"cuda\", 'timestep': 0.1, 'log_interval': 10}\n",
    "sampler = MolecularDynamics()\n",
    "n_models = 1\n",
    "n_qc_workers = 8\n",
    "min_run_length = 1\n",
    "max_run_length = 100\n",
    "energy_tolerance = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train model pretreat\n",
    "\n",
    "# Apply wrappers to functions that will be used to fix certain requirements\n",
    "def _wrap(func, **kwargs):\n",
    "    out = partial(func, **kwargs)\n",
    "    update_wrapper(out, func)\n",
    "    return out\n",
    "\n",
    "## MD objectives\n",
    "@dataclass\n",
    "class Trajectory:\n",
    "    \"\"\"Tracks the state of searching along individual trajectories\n",
    "\n",
    "    We mark the starting point, the last point produced from sampling,\n",
    "    and the last point we produced that has been validated\n",
    "    \"\"\"\n",
    "    id: int  # ID number of the\n",
    "    starting: ase.Atoms  # Starting point of the trajectory\n",
    "    current_timestep = 0  # How many timesteps have been used so far\n",
    "    last_validated: ase.Atoms = None  # Last validated point on the trajectory\n",
    "    current: ase.Atoms = None  # Last point produced along the trajectory\n",
    "    last_run_length: int = 0  # How long between current and last_validated\n",
    "    name: str = None  # Name of the trajectory\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.last_validated = self.current = self.starting\n",
    "\n",
    "    def update_current_structure(self, strc: ase.Atoms, run_length: int):\n",
    "        \"\"\"Update the structure that has yet to be updated\n",
    "\n",
    "        Args:\n",
    "            strc: Structure produced by sampling\n",
    "            run_length: How many timesteps were performed in sampling run\n",
    "        \"\"\"\n",
    "        self.current = strc.copy()\n",
    "        self.last_run_length = run_length\n",
    "\n",
    "    def set_validation(self, success: bool):\n",
    "        \"\"\"Set whether the trajectory was successfully validated\n",
    "\n",
    "        Args:\n",
    "            success: Whether the validation was successful\n",
    "        \"\"\"\n",
    "        if success:\n",
    "            self.last_validated = self.current  # Move the last validated forward\n",
    "            self.current_timestep += self.last_run_length\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SimulationTask:\n",
    "    atoms: ase.Atoms  # Structure to be run\n",
    "    traj_id: int  # Which trajectory this came from\n",
    "    ml_eng: float  # Energy predicted from machine learning model\n",
    "    ml_std: Optional[float] = None  # Uncertainty of the model\n",
    "\n",
    "## get model\n",
    "schnet = GCSchNetForcefield(starting_model)\n",
    "\n",
    "## copy training data\n",
    "train_path = out_dir / \"train.db\" \n",
    "shutil.copyfile(training_set, train_path)\n",
    "\n",
    "### wrap functions\n",
    "## train model\n",
    "my_train_schnet = _wrap(schnet.train, num_epochs=num_epochs, device='cuda',\n",
    "                        patience=8, reset_weights=False,\n",
    "                        huber_deltas=huber_deltas)\n",
    "\n",
    "## evaluate model\n",
    "my_eval_schnet = _wrap(schnet.evaluate, device='cuda')\n",
    "\n",
    "## use model sampling\n",
    "my_run_dynamics = _wrap(sampler.run_sampling, **sampler_kwargs)\n",
    "\n",
    "### prepare input\n",
    "# Load in the search space\n",
    "with connect(search_path) as db:\n",
    "    search_space = [Trajectory(i, x.toatoms(), name=x.get('filename', f'traj-{i}')) for i, x in enumerate(db.select(''))]\n",
    "    shuffle(search_space)\n",
    "    search_space = deque(search_space)\n",
    "    \n",
    "# Load in the training dataset\n",
    "with connect(train_path) as db:\n",
    "    all_examples = np.array([x.toatoms() for x in db.select(\"\")], dtype=object)\n",
    "\n",
    "    # Remove the unrealistic structures\n",
    "    # if self.max_force is not None:\n",
    "    #     all_examples = [a for a in all_examples if np.abs(a.get_forces()).max() < max_force]\n",
    "\n",
    "## search space queue\n",
    "to_audit: dict[int, Trajectory] = {}  # Trajectories that need to be audited\n",
    "audit_results: deque[float] = deque(maxlen=50) # Results of the last 50 audits\n",
    "\n",
    "# Prepare the initial model\n",
    "StartModelMessage = TorchMessage(starting_model)\n",
    "ActiveModelMessage = SchnetCalculator(starting_model) \n",
    "# Prepare the dataset\n",
    "train_sets = []\n",
    "valid_sets = []\n",
    "n_train = int(len(all_examples) * 0.9)\n",
    "for _ in range(n_models):\n",
    "    shuffle(all_examples)\n",
    "    train_sets.append(all_examples[:n_train])\n",
    "    valid_sets.append(all_examples[n_train:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train model\n",
    "for i in range(0, 1):\n",
    "    model_msgs = []\n",
    "    train_logs = []\n",
    "    for i, train_set in enumerate(valid_sets):\n",
    "        model_msg, train_log = my_train_schnet(model_msg=StartModelMessage,train_data = train_set, valid_data = valid_sets[i])\n",
    "        model_msgs.append(model_msg)\n",
    "        train_logs.append(train_log)\n",
    "\n",
    "    ## store model\n",
    "    # now we just test one model \n",
    "    model_save_path = out_dir / \"model.pth\"\n",
    "    with open(model_save_path, 'wb') as fp:\n",
    "        torch.save(model_msgs[0].get_model(), fp)\n",
    "    # Save the training data\n",
    "    with open(out_dir / 'training-history.json', 'a') as fp:\n",
    "        print(json.dumps(train_logs[0].to_dict(orient='list')), file=fp)\n",
    "        \n",
    "    active_model_proxy = SchnetCalculator(model_msgs[0].get_model())\n",
    "    StartModelMessage = TorchMessage(model_msgs[0].get_model())\n",
    "    model_msgs = []\n",
    "    train_logs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use model for sampling\n",
    "# Pick the next eligible trajectory and start from the last validated structure\n",
    "trajectory = search_space.popleft()\n",
    "starting_point = trajectory.starting\n",
    "\n",
    "# Initialize the structure if need be\n",
    "if trajectory.current_timestep == 0:\n",
    "    MaxwellBoltzmannDistribution(starting_point, temperature_K=100)\n",
    "    print('Initialized temperature to 100K')\n",
    "# Add the structure to a list of those being validated\n",
    "to_audit[trajectory.id] = trajectory\n",
    "\n",
    "# Determine the run length based on observations of errors\n",
    "run_length = min_run_length\n",
    "if len(audit_results) > n_qc_workers:\n",
    "    # Predict run length given audit error\n",
    "    error_per_step = np.median(audit_results)\n",
    "    target_error = energy_tolerance * 2\n",
    "    estimated_run_length = int(target_error / error_per_step)\n",
    "    print(f'Estimated run length of {estimated_run_length} steps to have an error of {target_error:.3f} eV/atom')\n",
    "    run_length = max(min_run_length, min(max_run_length, estimated_run_length))  # Keep to within the user-defined bounds\n",
    "    \n",
    "\n",
    "my_run_dynamics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
