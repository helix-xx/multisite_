{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Mar 26 23:17:38 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 31%   35C    P8               7W / 250W |      2MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:0B:00.0 Off |                  N/A |\n",
      "| 31%   35C    P8              23W / 250W |      2MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:0C:00.0 Off |                  N/A |\n",
      "| 31%   34C    P8               4W / 250W |      2MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:1B:00.0 Off |                  N/A |\n",
      "| 31%   33C    P8              19W / 250W |      2MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# test train task\n",
    "# train a model with enough runs\n",
    "# compare results with default MD DFT\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import logging\n",
    "import shutil\n",
    "from collections import deque\n",
    "from dataclasses import dataclass\n",
    "from random import shuffle, sample\n",
    "from typing import Dict, Any, Optional\n",
    "import json\n",
    "from functools import partial, update_wrapper\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import ase\n",
    "from ase.db import connect\n",
    "from ase.md.velocitydistribution import MaxwellBoltzmannDistribution\n",
    "from fff.learning.gc.ase import SchnetCalculator\n",
    "from fff.learning.gc.functions import GCSchNetForcefield\n",
    "from fff.learning.gc.models import SchNet, load_pretrained_model\n",
    "from fff.learning.util.messages import TorchMessage\n",
    "from fff.sampling.md import MolecularDynamics\n",
    "from fff.simulation import run_calculator, _run_calculator\n",
    "from fff.simulation.utils import read_from_string, write_to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "## pynvml\n",
    "import pynvml\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "# def get_gpu_info():\n",
    "#     gpu_info = {}\n",
    "#     try:\n",
    "#         pynvml.nvmlInit()\n",
    "#         device_count = pynvml.nvmlDeviceGetCount()\n",
    "#         for i in range(device_count):\n",
    "#             handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
    "#             gpu_name = pynvml.nvmlDeviceGetName(handle).decode('utf-8')\n",
    "#             gpu_info[f'GPU {i+1}'] = gpu_name.strip()\n",
    "#         pynvml.nvmlShutdown()\n",
    "#     except pynvml.NVMLError as error:\n",
    "#         print(\"Error: Failed to retrieve GPU information -\", error)\n",
    "#     return gpu_info\n",
    "\n",
    "# # 调用函数获取GPU信息并存储在字典中\n",
    "# gpu_dict = get_gpu_info()\n",
    "\n",
    "# # 打印GPU字典\n",
    "# for gpu, model in gpu_dict.items():\n",
    "#     print(f\"{gpu}: {model}\")\n",
    "\n",
    "# torch.distributed.init_process_group(backend=\"nccl\")\n",
    "print(torch.cuda.device_count())\n",
    "device = torch.device('cuda:1')\n",
    "print(device)\n",
    "# print(torch.distributed.get_rank())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path and varaibles\n",
    "multisite_path = \"/home/lizz_lab/cse12232433/project/colmena/multisite_\"\n",
    "training_set = multisite_path + \\\n",
    "    \"/data/forcefields/starting-model/initial-database.db\"\n",
    "model_path = multisite_path + \"/data/forcefields/starting-model/starting-model\"\n",
    "search_path = training_set\n",
    "out_dir = Path(multisite_path) / f\"my_test/temp\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "starting_model = torch.load(model_path, map_location='cpu')\n",
    "\n",
    "num_epochs = 128\n",
    "huber_deltas = (1, 10)\n",
    "sampler_kwargs = {'device': \"cpu\", 'timestep': 0.1, 'log_interval': 10}\n",
    "sampler = MolecularDynamics()\n",
    "n_models = 1\n",
    "n_qc_workers = 8\n",
    "min_run_length = 200\n",
    "max_run_length = 2000\n",
    "energy_tolerance = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model pretreat\n",
    "\n",
    "# Apply wrappers to functions that will be used to fix certain requirements\n",
    "def _wrap(func, **kwargs):\n",
    "    out = partial(func, **kwargs)\n",
    "    update_wrapper(out, func)\n",
    "    return out\n",
    "\n",
    "# MD objectives\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Trajectory:\n",
    "    \"\"\"Tracks the state of searching along individual trajectories\n",
    "\n",
    "    We mark the starting point, the last point produced from sampling,\n",
    "    and the last point we produced that has been validated\n",
    "    \"\"\"\n",
    "    id: int  # ID number of the\n",
    "    starting: ase.Atoms  # Starting point of the trajectory\n",
    "    current_timestep = 0  # How many timesteps have been used so far\n",
    "    last_validated: ase.Atoms = None  # Last validated point on the trajectory\n",
    "    current: ase.Atoms = None  # Last point produced along the trajectory\n",
    "    last_run_length: int = 0  # How long between current and last_validated\n",
    "    name: str = None  # Name of the trajectory\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.last_validated = self.current = self.starting\n",
    "\n",
    "    def update_current_structure(self, strc: ase.Atoms, run_length: int):\n",
    "        \"\"\"Update the structure that has yet to be updated\n",
    "\n",
    "        Args:\n",
    "            strc: Structure produced by sampling\n",
    "            run_length: How many timesteps were performed in sampling run\n",
    "        \"\"\"\n",
    "        self.current = strc.copy()\n",
    "        self.last_run_length = run_length\n",
    "\n",
    "    def set_validation(self, success: bool):\n",
    "        \"\"\"Set whether the trajectory was successfully validated\n",
    "\n",
    "        Args:\n",
    "            success: Whether the validation was successful\n",
    "        \"\"\"\n",
    "        if success:\n",
    "            self.last_validated = self.current  # Move the last validated forward\n",
    "            self.current_timestep += self.last_run_length\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SimulationTask:\n",
    "    atoms: ase.Atoms  # Structure to be run\n",
    "    traj_id: int  # Which trajectory this came from\n",
    "    ml_eng: float  # Energy predicted from machine learning model\n",
    "    ml_std: Optional[float] = None  # Uncertainty of the model\n",
    "\n",
    "\n",
    "# get model\n",
    "schnet = GCSchNetForcefield(starting_model)\n",
    "\n",
    "# copy training data\n",
    "train_path = out_dir / \"train.db\"\n",
    "shutil.copyfile(training_set, train_path)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "# wrap functions\n",
    "# train model\n",
    "my_train_schnet = _wrap(schnet.train, num_epochs=num_epochs, device=device,\n",
    "                        patience=8, reset_weights=False,\n",
    "                        huber_deltas=huber_deltas)\n",
    "\n",
    "# evaluate model\n",
    "my_eval_schnet = _wrap(schnet.evaluate, device=device)\n",
    "\n",
    "# use model sampling\n",
    "my_run_dynamics = _wrap(sampler.run_sampling, **sampler_kwargs)\n",
    "\n",
    "\n",
    "# prepare input\n",
    "# Load in the search space\n",
    "with connect(search_path) as db:\n",
    "    search_space = [Trajectory(i, x.toatoms(), name=x.get(\n",
    "        'filename', f'traj-{i}')) for i, x in enumerate(db.select(''))]\n",
    "    shuffle(search_space)\n",
    "    search_space = deque(search_space)\n",
    "\n",
    "# Load in the training dataset\n",
    "with connect(train_path) as db:\n",
    "    all_examples = np.array([x.toatoms() for x in db.select(\"\")], dtype=object)\n",
    "\n",
    "    # Remove the unrealistic structures\n",
    "    # if self.max_force is not None:\n",
    "    #     all_examples = [a for a in all_examples if np.abs(a.get_forces()).max() < max_force]\n",
    "\n",
    "# search space queue\n",
    "to_audit: dict[int, Trajectory] = {}  # Trajectories that need to be audited\n",
    "audit_results: deque[float] = deque(maxlen=50)  # Results of the last 50 audits\n",
    "task_queue_audit = []\n",
    "\n",
    "# Prepare the initial model\n",
    "StartModelMessage = TorchMessage(starting_model)\n",
    "ActiveModelMessage = SchnetCalculator(starting_model)\n",
    "# Prepare the dataset\n",
    "train_sets = []\n",
    "valid_sets = []\n",
    "n_train = int(len(all_examples) * 0.9)\n",
    "for _ in range(n_models):\n",
    "    shuffle(all_examples)\n",
    "    train_sets.append(all_examples[:n_train])\n",
    "    valid_sets.append(all_examples[n_train:])\n",
    "\n",
    "# store model and log\n",
    "model_msgs = []\n",
    "train_logs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "Caught StopIteration in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/lizz_lab/cse12232433/miniconda3/envs/multisite/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/lizz_lab/cse12232433/miniconda3/envs/multisite/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/lizz_lab/cse12232433/project/colmena/multisite_/finetuning-surrogates/fff/learning/gc/models.py\", line 191, in forward\n    device = next(self.parameters()).device\nStopIteration\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, train_set \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(valid_sets):\n\u001b[0;32m----> 4\u001b[0m         model_msg, train_log \u001b[38;5;241m=\u001b[39m \u001b[43mmy_train_schnet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_msg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStartModelMessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m         model_msgs\u001b[38;5;241m.\u001b[39mappend(model_msg)\n\u001b[1;32m      7\u001b[0m         train_logs\u001b[38;5;241m.\u001b[39mappend(train_log)\n",
      "File \u001b[0;32m~/project/colmena/multisite_/finetuning-surrogates/fff/learning/gc/functions.py:149\u001b[0m, in \u001b[0;36mGCSchNetForcefield.train\u001b[0;34m(self, model_msg, train_data, valid_data, num_epochs, device, batch_size, learning_rate, huber_deltas, energy_weight, reset_weights, patience, cpu, gpu)\u001b[0m\n\u001b[1;32m    146\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# Compute the energy and forces\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m energy, force \u001b[38;5;241m=\u001b[39m \u001b[43meval_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# Get the forces in energy and forces\u001b[39;00m\n\u001b[1;32m    152\u001b[0m energy_loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mhuber_loss(energy \u001b[38;5;241m/\u001b[39m batch\u001b[38;5;241m.\u001b[39mn_atoms, batch\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m/\u001b[39m batch\u001b[38;5;241m.\u001b[39mn_atoms, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, delta\u001b[38;5;241m=\u001b[39mhuber_eng)\n",
      "File \u001b[0;32m~/project/colmena/multisite_/finetuning-surrogates/fff/learning/gc/functions.py:34\u001b[0m, in \u001b[0;36meval_batch\u001b[0;34m(model, batch)\u001b[0m\n\u001b[1;32m     31\u001b[0m batch\u001b[38;5;241m.\u001b[39mpos\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# batch = batch.to(next(model.parameters()).device)\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m energ_batch \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m force_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(energ_batch, batch\u001b[38;5;241m.\u001b[39mpos, grad_outputs\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mones_like(energ_batch), retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m energ_batch, force_batch\n",
      "File \u001b[0;32m~/miniconda3/envs/multisite/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/multisite/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:168\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    167\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 168\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/multisite/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:178\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas, inputs, kwargs):\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/multisite/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py:86\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     84\u001b[0m     output \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m---> 86\u001b[0m         \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/multisite/lib/python3.9/site-packages/torch/_utils.py:461\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 461\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mStopIteration\u001b[0m: Caught StopIteration in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/lizz_lab/cse12232433/miniconda3/envs/multisite/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/lizz_lab/cse12232433/miniconda3/envs/multisite/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/lizz_lab/cse12232433/project/colmena/multisite_/finetuning-surrogates/fff/learning/gc/models.py\", line 191, in forward\n    device = next(self.parameters()).device\nStopIteration\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "for i in range(0, 1):\n",
    "    for i, train_set in enumerate(valid_sets):\n",
    "        model_msg, train_log = my_train_schnet(\n",
    "            model_msg=StartModelMessage, train_data=train_set, valid_data=valid_sets[i])\n",
    "        model_msgs.append(model_msg)\n",
    "        train_logs.append(train_log)\n",
    "\n",
    "    # store model\n",
    "    # now we just test one model\n",
    "    model_save_path = out_dir / \"model.pth\"\n",
    "    with open(model_save_path, 'wb') as fp:\n",
    "        torch.save(model_msgs[0].get_model(), fp)\n",
    "    # Save the training data\n",
    "    with open(out_dir / 'training-history.json', 'a') as fp:\n",
    "        print(json.dumps(train_logs[0].to_dict(orient='list')), file=fp)\n",
    "\n",
    "    active_model_proxy = SchnetCalculator(model_msgs[0].get_model())\n",
    "    StartModelMessage = TorchMessage(model_msgs[0].get_model())\n",
    "    model_msgs = []\n",
    "    train_logs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized temperature to 100K\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'active_model_proxy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 30\u001b[0m\n\u001b[1;32m     25\u001b[0m     run_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(min_run_length, \u001b[38;5;28mmin\u001b[39m(\n\u001b[1;32m     26\u001b[0m         max_run_length, estimated_run_length))\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# do sampling\u001b[39;00m\n\u001b[1;32m     29\u001b[0m audit, traj \u001b[38;5;241m=\u001b[39m my_run_dynamics(\n\u001b[0;32m---> 30\u001b[0m     atoms\u001b[38;5;241m=\u001b[39mstarting_point, steps\u001b[38;5;241m=\u001b[39mrun_length, calc\u001b[38;5;241m=\u001b[39m\u001b[43mactive_model_proxy\u001b[49m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# print(audit)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# print(len(traj))\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# add to list\u001b[39;00m\n\u001b[1;32m     34\u001b[0m to_audit[trajectory\u001b[38;5;241m.\u001b[39mid]\u001b[38;5;241m.\u001b[39mupdate_current_structure(audit, run_length)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'active_model_proxy' is not defined"
     ]
    }
   ],
   "source": [
    "# use model for sampling\n",
    "# sampling tasks loop\n",
    "for i in range(0, 100):\n",
    "    # Pick the next eligible trajectory and start from the last validated structure\n",
    "    trajectory = search_space.popleft()\n",
    "    starting_point = trajectory.starting\n",
    "\n",
    "    # Initialize the structure if need be\n",
    "    if trajectory.current_timestep == 0:\n",
    "        MaxwellBoltzmannDistribution(starting_point, temperature_K=100)\n",
    "        print('Initialized temperature to 100K')\n",
    "    # Add the structure to a list of those being validated\n",
    "    to_audit[trajectory.id] = trajectory\n",
    "\n",
    "    # Determine the run length based on observations of errors\n",
    "    run_length = min_run_length\n",
    "    if len(audit_results) > n_qc_workers:\n",
    "        # Predict run length given audit error\n",
    "        error_per_step = np.median(audit_results)\n",
    "        target_error = energy_tolerance * 2\n",
    "        estimated_run_length = int(target_error / error_per_step)\n",
    "        print(\n",
    "            f'Estimated run length of {estimated_run_length} steps to have an error of {target_error:.3f} eV/atom')\n",
    "        # Keep to within the user-defined bounds\n",
    "        run_length = max(min_run_length, min(\n",
    "            max_run_length, estimated_run_length))\n",
    "\n",
    "    # do sampling\n",
    "    audit, traj = my_run_dynamics(\n",
    "        atoms=starting_point, steps=run_length, calc=active_model_proxy)\n",
    "    # print(audit)\n",
    "    # print(len(traj))\n",
    "    # add to list\n",
    "    to_audit[trajectory.id].update_current_structure(audit, run_length)\n",
    "    task_queue_audit.append(SimulationTask(\n",
    "        atoms=traj[-1], traj_id=trajectory.id, ml_eng=traj[-1].get_potential_energy()))\n",
    "\n",
    "print(len(task_queue_audit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store sampling result\n",
    "import pickle\n",
    "with open(out_dir / 'task_queue_audit', 'wb') as fp:\n",
    "    pickle.dump(task_queue_audit, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Threads set to 24 by Python driver.\n",
      "  Threads set to 24 by Python driver.\n",
      "0.07407622481029345\n"
     ]
    }
   ],
   "source": [
    "# test simulation\n",
    "# real MD simulation\n",
    "tempdir = \"./temp\"\n",
    "\n",
    "# set calculator\n",
    "calc = dict(calc='psi4', method='pbe0-d3', basis='aug-cc-pvdz', num_threads=24)\n",
    "my_run_simulation = _wrap(run_calculator, calc=calc, temp_path=tempdir)\n",
    "\n",
    "# prepare input\n",
    "to_run = task_queue_audit[-1]\n",
    "ml_eng = to_run.ml_eng\n",
    "atoms = to_run.atoms\n",
    "atoms.set_center_of_mass([0, 0, 0])\n",
    "xyz = write_to_string(atoms, 'xyz')\n",
    "\n",
    "# run\n",
    "value = my_run_simulation(xyz)\n",
    "\n",
    "# result\n",
    "atoms = read_from_string(value, 'json')\n",
    "dft_energy = atoms.get_potential_energy()\n",
    "diff_energy = abs(dft_energy - ml_eng) / len(atoms)\n",
    "print(diff_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple grid search\n",
    "import time\n",
    "import itertools\n",
    "from ase.build import molecule\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from fff.simulation import run_calculator, _run_calculator\n",
    "from fff.simulation.utils import read_from_string, write_to_string\n",
    "\n",
    "parameter_space = []\n",
    "tempdir = \"./temp\"\n",
    "\n",
    "def generate_search_space(num_cpus, max_parallelism):\n",
    "    search_space = []\n",
    "    for parallelism in range(1, max_parallelism + 1):\n",
    "        combinations = itertools.combinations_with_replacement(\n",
    "            range(1, num_cpus + 1), parallelism)\n",
    "        for combination in combinations:\n",
    "            if sum(combination) == num_cpus:\n",
    "                search_space.append(combination)\n",
    "    return search_space\n",
    "\n",
    "\n",
    "def bundle_simulation_task(run_parames=[8, 8, 8], atoms_queue=[]):\n",
    "    # simulation here\n",
    "    atoms = []\n",
    "    task_infos = []\n",
    "    # for _ in range(0,len(run_parames)):\n",
    "    #     ##TODO we should choose proper atoms here\n",
    "    #     atoms.append(atoms_queue.pop())\n",
    "    \n",
    "    # simple test\n",
    "    # atoms.append(molecule('H2O'))\n",
    "    atoms = molecule('H2O')\n",
    "    with ProcessPoolExecutor(max_workers=len(run_parames)) as exe:\n",
    "        start_times = {}\n",
    "        futs = []\n",
    "        for i,cpus in enumerate(run_parames):\n",
    "            # atoms[0].set_center_of_mass([0, 0, 0])\n",
    "            xyz = write_to_string(atoms, 'xyz')\n",
    "            calc = dict(calc='psi4', method='pbe0-d3', basis='aug-cc-pvdz', num_threads=cpus)            \n",
    "            \n",
    "            fut = exe.submit(_run_calculator, str(xyz), calc, tempdir)\n",
    "            start_times[fut] = time.time()\n",
    "            futs.append(fut)\n",
    "            \n",
    "    execution_times = []\n",
    "    for fut in as_completed(futs):\n",
    "        execution_times.append(time.time() - start_times[fut])\n",
    "        calculated = read_from_string(fut.result(), 'json')\n",
    "        dft_energy = calculated.get_potential_energy()\n",
    "        # diff_energy = abs(dft_energy - ml_eng) / len(calculated)\n",
    "\n",
    "    # task_info = {\n",
    "    #     'atoms': calculated,\n",
    "    #     'run_parames': cpus,\n",
    "    #     'time': end - start,\n",
    "    #     #TODO 'ml_eng' : to_run.ml_eng,\n",
    "    #     'dft_eng': dft_energy,\n",
    "    # }\n",
    "    # task_infos.append(task_info)\n",
    "    return execution_times\n",
    "\n",
    "\n",
    "num_cpus = 24\n",
    "max_parallelism = 8\n",
    "parameter_space = generate_search_space(num_cpus, max_parallelism)\n",
    "\n",
    "print(len(parameter_space))\n",
    "print(parameter_space)\n",
    "\n",
    "gird_results = []\n",
    "for run_parames in parameter_space:\n",
    "    gird_results.append((run_parames,bundle_simulation_task(run_parames)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "821\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(len(gird_results))\n",
    "\n",
    "with open('./temp/grid_results.json', 'w') as json_file:\n",
    "    json.dump(gird_results, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Threads set to 24 by Python driver.\n",
      "  Threads set to 24 by Python driver.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Calculation failed: \nFatal Error: Matrix::power: C_DSYEV failed\nError occurred in file: /scratch/psilocaluser/conda-builds/psi4-multiout_1657298395608/work/psi4/src/psi4/libmints/matrix.cc on line: 2330\nThe most recent 5 function calls were:\n\npsi::FittingMetric::form_eig_inverse(double)\npsi::DiskDFJK::preiterations()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/yxx/work/project/colmena/multisite_/finetuning-surrogates/fff/simulation/__init__.py\", line 54, in _run_calculator\n    atoms.get_forces()\n  File \"/home/yxx/miniconda3/envs/multisite/lib/python3.9/site-packages/ase/atoms.py\", line 788, in get_forces\n    forces = self._calc.get_forces(self)\n  File \"/home/yxx/miniconda3/envs/multisite/lib/python3.9/site-packages/ase/calculators/abc.py\", line 23, in get_forces\n    return self.get_property('forces', atoms)\n  File \"/home/yxx/miniconda3/envs/multisite/lib/python3.9/site-packages/ase/calculators/calculator.py\", line 737, in get_property\n    self.calculate(atoms, [name], system_changes)\n  File \"/home/yxx/miniconda3/envs/multisite/lib/python3.9/site-packages/ase/calculators/psi4.py\", line 179, in calculate\n    grad, wf = self.psi4.driver.gradient('{}/{}'.format(method, basis),\n  File \"/home/yxx/miniconda3/envs/multisite/lib/python3.9/site-packages/psi4/driver/driver.py\", line 619, in gradient\n    wfn = procedures['gradient'][lowername](lowername, molecule=molecule, **kwargs)\n  File \"/home/yxx/miniconda3/envs/multisite/lib/python3.9/site-packages/psi4/driver/procrouting/proc.py\", line 90, in select_scf_gradient\n    return func(name, **kwargs)\n  File \"/home/yxx/miniconda3/envs/multisite/lib/python3.9/site-packages/psi4/driver/procrouting/proc.py\", line 2550, in run_scf_gradient\n    ref_wfn = run_scf(name, **kwargs)\n  File \"/home/yxx/miniconda3/envs/multisite/lib/python3.9/site-packages/psi4/driver/procrouting/proc.py\", line 2455, in run_scf\n    scf_wfn = scf_helper(name, post_scf=False, **kwargs)\n  File \"/home/yxx/miniconda3/envs/multisite/lib/python3.9/site-packages/psi4/driver/procrouting/proc.py\", line 1670, in scf_helper\n    e_scf = scf_wfn.compute_energy()\n  File \"/home/yxx/miniconda3/envs/multisite/lib/python3.9/site-packages/psi4/driver/procrouting/scf_proc/scf_iterator.py\", line 83, in scf_compute_energy\n    self.initialize()\n  File \"/home/yxx/miniconda3/envs/multisite/lib/python3.9/site-packages/psi4/driver/procrouting/scf_proc/scf_iterator.py\", line 193, in scf_initialize\n    self.initialize_jk(self.memory_jk_, jk=jk)\n  File \"/home/yxx/miniconda3/envs/multisite/lib/python3.9/site-packages/psi4/driver/procrouting/scf_proc/scf_iterator.py\", line 128, in initialize_jk\n    jk.initialize()\nRuntimeError: \nFatal Error: Matrix::power: C_DSYEV failed\nError occurred in file: /scratch/psilocaluser/conda-builds/psi4-multiout_1657298395608/work/psi4/src/psi4/libmints/matrix.cc on line: 2330\nThe most recent 5 function calls were:\n\npsi::FittingMetric::form_eig_inverse(double)\npsi::DiskDFJK::preiterations()\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/yxx/miniconda3/envs/multisite/lib/python3.9/concurrent/futures/process.py\", line 246, in _process_worker\n    r = call_item.fn(*call_item.args, **call_item.kwargs)\n  File \"/home/yxx/work/project/colmena/multisite_/finetuning-surrogates/fff/simulation/__init__.py\", line 57, in _run_calculator\n    raise ValueError(f'Calculation failed: {exc}')\nValueError: Calculation failed: \nFatal Error: Matrix::power: C_DSYEV failed\nError occurred in file: /scratch/psilocaluser/conda-builds/psi4-multiout_1657298395608/work/psi4/src/psi4/libmints/matrix.cc on line: 2330\nThe most recent 5 function calls were:\n\npsi::FittingMetric::form_eig_inverse(double)\npsi::DiskDFJK::preiterations()\n\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/yxx/work/project/colmena/multisite_/my_test/training_task_test.ipynb Cell 11\u001b[0m line \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu_2/home/yxx/work/project/colmena/multisite_/my_test/training_task_test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m xyz \u001b[39m=\u001b[39m write_to_string(atoms, \u001b[39m'\u001b[39m\u001b[39mxyz\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu_2/home/yxx/work/project/colmena/multisite_/my_test/training_task_test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m# run\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu_2/home/yxx/work/project/colmena/multisite_/my_test/training_task_test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m value \u001b[39m=\u001b[39m my_run_simulation(xyz)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu_2/home/yxx/work/project/colmena/multisite_/my_test/training_task_test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m# result\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu_2/home/yxx/work/project/colmena/multisite_/my_test/training_task_test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m atoms \u001b[39m=\u001b[39m read_from_string(value, \u001b[39m'\u001b[39m\u001b[39mjson\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/work/project/colmena/multisite_/finetuning-surrogates/fff/simulation/__init__.py:32\u001b[0m, in \u001b[0;36mrun_calculator\u001b[0;34m(xyz, calc, temp_path)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mwith\u001b[39;00m ProcessPoolExecutor(max_workers\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39mas\u001b[39;00m exe:\n\u001b[1;32m     31\u001b[0m     fut \u001b[39m=\u001b[39m exe\u001b[39m.\u001b[39msubmit(_run_calculator, \u001b[39mstr\u001b[39m(xyz), calc, temp_path)  \u001b[39m# str ensures proxies are resolved\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n",
      "File \u001b[0;32m~/miniconda3/envs/multisite/lib/python3.9/concurrent/futures/_base.py:446\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    445\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 446\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/miniconda3/envs/multisite/lib/python3.9/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Calculation failed: \nFatal Error: Matrix::power: C_DSYEV failed\nError occurred in file: /scratch/psilocaluser/conda-builds/psi4-multiout_1657298395608/work/psi4/src/psi4/libmints/matrix.cc on line: 2330\nThe most recent 5 function calls were:\n\npsi::FittingMetric::form_eig_inverse(double)\npsi::DiskDFJK::preiterations()\n"
     ]
    }
   ],
   "source": [
    "# test pickle serialization\n",
    "\n",
    "with open(out_dir / 'task_queue_audit', 'rb') as fp:\n",
    "    task_queue_audit_test = pickle.load(fp)\n",
    "\n",
    "# test simulation\n",
    "# real MD simulation\n",
    "tempdir = \"./temp\"\n",
    "\n",
    "# set calculator\n",
    "calc = dict(calc='psi4', method='pbe0-d3', basis='aug-cc-pvdz', num_threads=24)\n",
    "my_run_simulation = _wrap(run_calculator, calc=calc, temp_path=tempdir)\n",
    "\n",
    "# prepare input\n",
    "\n",
    "# to_run = task_queue_audit_test[-1]\n",
    "# ml_eng = to_run.ml_eng\n",
    "# atoms = to_run.atoms\n",
    "# atoms.set_center_of_mass([0, 0, 0])\n",
    "\n",
    "# atoms = molecule('H2O')\n",
    "# xyz = write_to_string(atoms, 'xyz')\n",
    "\n",
    "# run\n",
    "# value = my_run_simulation(xyz)\n",
    "\n",
    "# result\n",
    "# atoms = read_from_string(value, 'json')\n",
    "# dft_energy = atoms.get_potential_energy()\n",
    "# diff_energy = abs(dft_energy - ml_eng) / len(atoms)\n",
    "# print(diff_energy)\n",
    "\n",
    "\n",
    "execution_times = []\n",
    "diff_energies = []\n",
    "simulation_lists = []\n",
    "for to_run in task_queue_audit_test:\n",
    "    start = time.time()\n",
    "    ml_eng = to_run.ml_eng\n",
    "    atoms = to_run.atoms\n",
    "    atoms.set_center_of_mass([0, 0, 0])\n",
    "    xyz = write_to_string(atoms, 'xyz')\n",
    "\n",
    "    # run\n",
    "    value = my_run_simulation(xyz)\n",
    "    \n",
    "    # result\n",
    "    atoms = read_from_string(value, 'json')\n",
    "    dft_energy = atoms.get_potential_energy()\n",
    "    diff_energy = abs(dft_energy - ml_eng) / len(atoms)\n",
    "    diff_energies.append(diff_energy)\n",
    "    simulation_lists.append(atoms)\n",
    "    execution_times.append(time.time() - start)\n",
    "    # print(diff_energy)\n",
    "\n",
    "data = []\n",
    "for x,y,z in simulation_lists,diff_energies,execution_times:\n",
    "    data.append((x,y,z))\n",
    "with open('./temp/simulation_tasks_execution_time.json', 'w') as json_file:\n",
    "    json.dump(data, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import logging\n",
    "import shutil\n",
    "from collections import deque\n",
    "from dataclasses import dataclass\n",
    "from random import shuffle, sample\n",
    "from typing import Dict, Any, Optional\n",
    "import json\n",
    "from functools import partial, update_wrapper\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import multiprocessing\n",
    "\n",
    "import ase\n",
    "from ase.db import connect\n",
    "from ase.md.velocitydistribution import MaxwellBoltzmannDistribution\n",
    "import fff\n",
    "from fff.learning.gc.ase import SchnetCalculator\n",
    "from fff.learning.gc.functions import GCSchNetForcefield\n",
    "from fff.learning.gc.models import SchNet, load_pretrained_model\n",
    "from fff.learning.util.messages import TorchMessage\n",
    "from fff.sampling.md import MolecularDynamics\n",
    "from fff.simulation import run_calculator, _run_calculator\n",
    "from fff.simulation.utils import read_from_string, write_to_string\n",
    "\n",
    "import os\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from contextlib import redirect_stderr\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "# path and varaibles\n",
    "multisite_path = \"/home/lizz_lab/cse12232433/project/colmena/multisite_\"\n",
    "training_set = multisite_path + \\\n",
    "    \"/data/forcefields/starting-model/initial-database.db\"\n",
    "model_path = multisite_path + \"/data/forcefields/starting-model/starting-model\"\n",
    "search_path = training_set\n",
    "out_dir = Path(multisite_path) / f\"my_test/temp\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "starting_model = torch.load(model_path, map_location='cpu')\n",
    "\n",
    "num_epochs = 12\n",
    "huber_deltas = (1, 10)\n",
    "sampler_kwargs = {'device': \"cpu\", 'timestep': 0.1, 'log_interval': 10}\n",
    "sampler = MolecularDynamics()\n",
    "n_models = 1\n",
    "n_qc_workers = 8\n",
    "min_run_length = 200\n",
    "max_run_length = 2000\n",
    "energy_tolerance = 0.1\n",
    "\n",
    "# train model pretreat\n",
    "\n",
    "# Apply wrappers to functions that will be used to fix certain requirements\n",
    "def _wrap(func, **kwargs):\n",
    "    out = partial(func, **kwargs)\n",
    "    update_wrapper(out, func)\n",
    "    return out\n",
    "\n",
    "# MD objectives\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Trajectory:\n",
    "    \"\"\"Tracks the state of searching along individual trajectories\n",
    "\n",
    "    We mark the starting point, the last point produced from sampling,\n",
    "    and the last point we produced that has been validated\n",
    "    \"\"\"\n",
    "    id: int  # ID number of the\n",
    "    starting: ase.Atoms  # Starting point of the trajectory\n",
    "    current_timestep = 0  # How many timesteps have been used so far\n",
    "    last_validated: ase.Atoms = None  # Last validated point on the trajectory\n",
    "    current: ase.Atoms = None  # Last point produced along the trajectory\n",
    "    last_run_length: int = 0  # How long between current and last_validated\n",
    "    name: str = None  # Name of the trajectory\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.last_validated = self.current = self.starting\n",
    "\n",
    "    def update_current_structure(self, strc: ase.Atoms, run_length: int):\n",
    "        \"\"\"Update the structure that has yet to be updated\n",
    "\n",
    "        Args:\n",
    "            strc: Structure produced by sampling\n",
    "            run_length: How many timesteps were performed in sampling run\n",
    "        \"\"\"\n",
    "        self.current = strc.copy()\n",
    "        self.last_run_length = run_length\n",
    "\n",
    "    def set_validation(self, success: bool):\n",
    "        \"\"\"Set whether the trajectory was successfully validated\n",
    "\n",
    "        Args:\n",
    "            success: Whether the validation was successful\n",
    "        \"\"\"\n",
    "        if success:\n",
    "            self.last_validated = self.current  # Move the last validated forward\n",
    "            self.current_timestep += self.last_run_length\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SimulationTask:\n",
    "    atoms: ase.Atoms  # Structure to be run\n",
    "    traj_id: int  # Which trajectory this came from\n",
    "    ml_eng: float  # Energy predicted from machine learning model\n",
    "    ml_std: Optional[float] = None  # Uncertainty of the model\n",
    "\n",
    "\n",
    "# get model\n",
    "schnet = GCSchNetForcefield(starting_model)\n",
    "\n",
    "# copy training data\n",
    "train_path = out_dir / \"train.db\"\n",
    "shutil.copyfile(training_set, train_path)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "# wrap functions\n",
    "# train model\n",
    "my_train_schnet = _wrap(schnet.train, num_epochs=num_epochs, device=device,\n",
    "                        patience=8, reset_weights=False,\n",
    "                        huber_deltas=huber_deltas)\n",
    "\n",
    "# evaluate model\n",
    "my_eval_schnet = _wrap(schnet.evaluate, device=device)\n",
    "\n",
    "# use model sampling\n",
    "my_run_dynamics = _wrap(sampler.run_sampling, **sampler_kwargs)\n",
    "\n",
    "\n",
    "# prepare input\n",
    "# Load in the search space\n",
    "with connect(search_path) as db:\n",
    "    search_space = [Trajectory(i, x.toatoms(), name=x.get(\n",
    "        'filename', f'traj-{i}')) for i, x in enumerate(db.select(''))]\n",
    "    shuffle(search_space)\n",
    "    search_space = deque(search_space)\n",
    "\n",
    "# Load in the training dataset\n",
    "with connect(train_path) as db:\n",
    "    all_examples = np.array([x.toatoms() for x in db.select(\"\")], dtype=object)\n",
    "\n",
    "    # Remove the unrealistic structures\n",
    "    # if self.max_force is not None:\n",
    "    #     all_examples = [a for a in all_examples if np.abs(a.get_forces()).max() < max_force]\n",
    "\n",
    "# search space queue\n",
    "to_audit: dict[int, Trajectory] = {}  # Trajectories that need to be audited\n",
    "audit_results: deque[float] = deque(maxlen=50)  # Results of the last 50 audits\n",
    "task_queue_audit = []\n",
    "\n",
    "# Prepare the initial model\n",
    "StartModelMessage = TorchMessage(starting_model)\n",
    "ActiveModelMessage = SchnetCalculator(starting_model)\n",
    "# Prepare the dataset\n",
    "train_sets = []\n",
    "valid_sets = []\n",
    "n_train = int(len(all_examples) * 0.9)\n",
    "for _ in range(n_models):\n",
    "    shuffle(all_examples)\n",
    "    train_sets.append(all_examples[:n_train])\n",
    "    valid_sets.append(all_examples[n_train:])\n",
    "\n",
    "# store model and log\n",
    "model_msgs = []\n",
    "train_logs = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'fff.learning.util.messages.TorchMessage'>\n",
      "   epoch      time  train_loss_force  train_loss_energy  train_loss_total  \\\n",
      "0      0  0.632660          0.174050           0.001451          0.156790   \n",
      "1      1  1.082573          1.044265           0.000632          0.939902   \n",
      "\n",
      "   valid_loss_force  valid_loss_energy  valid_loss_total  \n",
      "0          0.945775           0.000142          0.851212  \n",
      "1          0.200702           0.000388          0.180671  \n",
      "running time -12.918474912643433\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(fff)\n",
    "\n",
    "\n",
    "schnet = fff.learning.gc.functions.GCSchNetForcefield(starting_model)\n",
    "## DDP\n",
    "train_data = train_sets[0]\n",
    "valid_data = valid_sets[0]\n",
    "gpu=[0,1,2,3]\n",
    "my_train_schnet = _wrap(schnet.train, num_epochs=2, patience=8, reset_weights=False, huber_deltas=huber_deltas,parallel=2)\n",
    "gpu=[2,3]\n",
    "# gpu_str = ','.join(map(str, gpu))\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = gpu_str\n",
    "for i in range(1):\n",
    "    start_time = time.time()\n",
    "    result,log = my_train_schnet(train_data=train_data,valid_data=valid_data, device=\"cuda\", gpu=gpu,cpu=4,model_msg=StartModelMessage)\n",
    "    # result, log = schnet.train(num_epochs=2,patience=8,reset_weights=False,huber_deltas=huber_deltas,train_data=train_data,valid_data=valid_data, device=\"cuda\", gpu=gpu,cpu=4,model_msg=StartModelMessage, parallel=2)\n",
    "    print(type(result))\n",
    "    print(log)\n",
    "    print(f\"running time {start_time - time.time()}\")\n",
    "\n",
    "# test multi process with DDP\n",
    "# gpu0 = [0,1]\n",
    "# gpu1 = [2,3]\n",
    "# p1 = multiprocessing.Process(target=my_train_schnet, kwargs={\"train_data\":train_data,\"valid_data\":valid_data,\"device\":\"cuda\", \"gpu\":gpu0,\"cpu\":4,\"model_msg\":StartModelMessage})\n",
    "# p2 = multiprocessing.Process(target=my_train_schnet, kwargs={\"train_data\":train_data,\"valid_data\":valid_data,\"device\":\"cuda\", \"gpu\":gpu1,\"cpu\":4,\"model_msg\":StartModelMessage})\n",
    "# p1.start()\n",
    "# p2.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0,3\n",
    "!echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<parsl.dataflow.dflow.DataFlowKernel at 0x7f9b08147040>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import parsl\n",
    "from parsl.executors import HighThroughputExecutor, WorkQueueExecutor\n",
    "from parsl.providers import CobaltProvider, AdHocProvider, SlurmProvider, LocalProvider\n",
    "from parsl.addresses import address_by_hostname\n",
    "from parsl.launchers import AprunLauncher,SrunLauncher\n",
    "from parsl.channels import SSHChannel, LocalChannel, SSHInteractiveLoginChannel\n",
    "from parsl import Config\n",
    "from parsl.app.app import python_app\n",
    "\n",
    "# 配置 Parsl 运行时\n",
    "local_config = Config(\n",
    "    executors=[\n",
    "        HighThroughputExecutor(\n",
    "            label=\"htex_Local\",\n",
    "            worker_debug=True,\n",
    "            available_accelerators=2,\n",
    "            provider=LocalProvider(\n",
    "                channel=LocalChannel(),\n",
    "                init_blocks=1,\n",
    "                max_blocks=1,\n",
    "                worker_init='''\n",
    "                which python\n",
    "                '''\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    "    strategy='none',\n",
    ")\n",
    "parsl.load(local_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<fff.learning.util.messages.TorchMessage object at 0x7f9a3f600580>,    epoch      time  train_loss_force  train_loss_energy  train_loss_total  \\\n",
      "0      0  0.870774          0.174067           0.001451          0.156805   \n",
      "1      1  1.414091          1.046277           0.000634          0.941713   \n",
      "\n",
      "   valid_loss_force  valid_loss_energy  valid_loss_total  \n",
      "0          0.945953           0.000142          0.851372  \n",
      "1          0.201242           0.000388          0.181156  )\n"
     ]
    }
   ],
   "source": [
    "# options = {'executors': 'all'}\n",
    "my_train = python_app(my_train_schnet)\n",
    "result1 = my_train(train_data=train_data,valid_data=valid_data, device=\"cuda\", gpu=[2,3],cpu=4,model_msg=starting_model)\n",
    "# result2 = my_train(train_data=train_data,valid_data=valid_data, device=\"cuda\", gpu=[1,2],cpu=4,model_msg=starting_model)\n",
    "print(result1.result())\n",
    "# print(result2.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[1533], y=[32], pos=[1533, 3], z=[1533], f=[1533, 3], n_atoms=[32], size=[32], batch=[1533], ptr=[33])\n",
      "torch.Size([1533, 3])\n",
      "torch.Size([1533, 3])\n"
     ]
    }
   ],
   "source": [
    "## origin\n",
    "import ase\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch.nn import functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.loader import DataListLoader\n",
    "\n",
    "from fff.learning.gc.data import AtomsDataset\n",
    "from fff.learning.gc.models import SchNet\n",
    "from fff.learning.base import BaseLearnableForcefield, ModelMsgType\n",
    "from fff.learning.util.messages import TorchMessage\n",
    "\n",
    "from torch_geometric.nn import data_parallel\n",
    "from torch_geometric.data import Batch\n",
    "## torch DDP, not completed\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "\n",
    "\n",
    "sch = GCSchNetForcefield()\n",
    "model = sch.get_model(StartModelMessage)\n",
    "\n",
    "# model = data_parallel.DataParallel(model)\n",
    "model.to('cuda')\n",
    "\n",
    "# Unpack some inputs\n",
    "huber_eng, huber_force = huber_deltas\n",
    "batch_size: int = 32\n",
    "learning_rate: float = 1e-3\n",
    "huber_deltas: (float, float) = (0.5, 1)\n",
    "energy_weight: float = 0.1\n",
    "reset_weights: bool = False\n",
    "patience: int = None\n",
    "train_data = train_sets[0]\n",
    "valid_data = valid_sets[0]\n",
    "num_epochs = 32\n",
    "\n",
    "\n",
    "# Start the training process\n",
    "with TemporaryDirectory(prefix='spk') as td:\n",
    "    td = Path(td)\n",
    "    # Save the batch to an ASE Atoms database\n",
    "    with open(os.devnull, 'w') as fp, redirect_stderr(fp):\n",
    "        train_dataset = AtomsDataset.from_atoms(train_data, td / 'train')\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        # train_loader = DataListLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        valid_dataset = AtomsDataset.from_atoms(valid_data, td / 'valid')\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "        # valid_loader = DataListLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "    # Make the trainer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    if patience is None:\n",
    "        patience = num_epochs // 8\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=patience, factor=0.8, min_lr=1e-6)\n",
    "\n",
    "    # Store the best loss\n",
    "    best_loss = torch.inf\n",
    "\n",
    "    # Loop over epochs\n",
    "    log = []\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        # Iterate over all batches in the training set\n",
    "        train_losses = defaultdict(list)\n",
    "        for batch in train_loader:\n",
    "            batch.to(device)\n",
    "            print(batch)\n",
    "            batch.pos.requires_grad = True\n",
    "            energy = model(batch)\n",
    "            force = -torch.autograd.grad(energy, batch.pos, grad_outputs=torch.ones_like(energy), retain_graph=True)[0]\n",
    "\n",
    "            # Get the forces in energy and forces\n",
    "            energy_loss = F.huber_loss(energy / batch.n_atoms, batch.y / batch.n_atoms, reduction='mean', delta=huber_eng)\n",
    "            force_loss = F.huber_loss(force, batch.f, reduction='mean', delta=huber_force)\n",
    "            print(force.size())\n",
    "            print(batch.f.size())\n",
    "            break\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "torch.Size([32])\n",
      "torch.Size([1533, 3])\n",
      "torch.Size([1533, 3])\n",
      "1533\n",
      "torch.Size([1533, 3])\n",
      "tensor([[-2.4443, -1.2409,  2.5896],\n",
      "        [-1.6220, -0.8657,  2.2367],\n",
      "        [-3.1409, -0.8484,  2.0540],\n",
      "        ...,\n",
      "        [ 2.2207,  3.9629,  0.8153],\n",
      "        [ 2.7830,  4.6864,  1.0768],\n",
      "        [ 2.7988,  3.2752,  0.4353]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "## no dataparallel\n",
    "print(batch.pos.requires_grad)\n",
    "batch.pos.requires_grad = True\n",
    "    \n",
    "energ_batch = model(batch)\n",
    "print(energ_batch.size())\n",
    "force_batch = -torch.autograd.grad(energ_batch, batch.pos, grad_outputs=torch.ones_like(energ_batch), retain_graph=True)[0]\n",
    "print(force_batch.size())\n",
    "print(batch.pos.size())\n",
    "print(len(batch.f))\n",
    "print(batch.f.size())\n",
    "print(batch.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data(x=[60], y=[1], pos=[60, 3], z=[60], f=[60, 3], n_atoms=[1], size=[1]), Data(x=[66], y=[1], pos=[66, 3], z=[66], f=[66, 3], n_atoms=[1], size=[1]), Data(x=[36], y=[1], pos=[36, 3], z=[36], f=[36, 3], n_atoms=[1], size=[1]), Data(x=[36], y=[1], pos=[36, 3], z=[36], f=[36, 3], n_atoms=[1], size=[1]), Data(x=[24], y=[1], pos=[24, 3], z=[24], f=[24, 3], n_atoms=[1], size=[1]), Data(x=[21], y=[1], pos=[21, 3], z=[21], f=[21, 3], n_atoms=[1], size=[1]), Data(x=[27], y=[1], pos=[27, 3], z=[27], f=[27, 3], n_atoms=[1], size=[1]), Data(x=[57], y=[1], pos=[57, 3], z=[57], f=[57, 3], n_atoms=[1], size=[1]), Data(x=[51], y=[1], pos=[51, 3], z=[51], f=[51, 3], n_atoms=[1], size=[1]), Data(x=[33], y=[1], pos=[33, 3], z=[33], f=[33, 3], n_atoms=[1], size=[1]), Data(x=[75], y=[1], pos=[75, 3], z=[75], f=[75, 3], n_atoms=[1], size=[1]), Data(x=[9], y=[1], pos=[9, 3], z=[9], f=[9, 3], n_atoms=[1], size=[1]), Data(x=[63], y=[1], pos=[63, 3], z=[63], f=[63, 3], n_atoms=[1], size=[1]), Data(x=[30], y=[1], pos=[30, 3], z=[30], f=[30, 3], n_atoms=[1], size=[1]), Data(x=[57], y=[1], pos=[57, 3], z=[57], f=[57, 3], n_atoms=[1], size=[1]), Data(x=[69], y=[1], pos=[69, 3], z=[69], f=[69, 3], n_atoms=[1], size=[1]), Data(x=[63], y=[1], pos=[63, 3], z=[63], f=[63, 3], n_atoms=[1], size=[1]), Data(x=[72], y=[1], pos=[72, 3], z=[72], f=[72, 3], n_atoms=[1], size=[1]), Data(x=[75], y=[1], pos=[75, 3], z=[75], f=[75, 3], n_atoms=[1], size=[1]), Data(x=[75], y=[1], pos=[75, 3], z=[75], f=[75, 3], n_atoms=[1], size=[1]), Data(x=[27], y=[1], pos=[27, 3], z=[27], f=[27, 3], n_atoms=[1], size=[1]), Data(x=[54], y=[1], pos=[54, 3], z=[54], f=[54, 3], n_atoms=[1], size=[1]), Data(x=[66], y=[1], pos=[66, 3], z=[66], f=[66, 3], n_atoms=[1], size=[1]), Data(x=[12], y=[1], pos=[12, 3], z=[12], f=[12, 3], n_atoms=[1], size=[1]), Data(x=[42], y=[1], pos=[42, 3], z=[42], f=[42, 3], n_atoms=[1], size=[1]), Data(x=[39], y=[1], pos=[39, 3], z=[39], f=[39, 3], n_atoms=[1], size=[1]), Data(x=[18], y=[1], pos=[18, 3], z=[18], f=[18, 3], n_atoms=[1], size=[1]), Data(x=[75], y=[1], pos=[75, 3], z=[75], f=[75, 3], n_atoms=[1], size=[1]), Data(x=[60], y=[1], pos=[60, 3], z=[60], f=[60, 3], n_atoms=[1], size=[1]), Data(x=[33], y=[1], pos=[33, 3], z=[33], f=[33, 3], n_atoms=[1], size=[1]), Data(x=[15], y=[1], pos=[15, 3], z=[15], f=[15, 3], n_atoms=[1], size=[1]), Data(x=[33], y=[1], pos=[33, 3], z=[33], f=[33, 3], n_atoms=[1], size=[1])]\n"
     ]
    }
   ],
   "source": [
    "import ase\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch.nn import functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.loader import DataListLoader\n",
    "\n",
    "from fff.learning.gc.data import AtomsDataset\n",
    "from fff.learning.gc.models import SchNet\n",
    "from fff.learning.base import BaseLearnableForcefield, ModelMsgType\n",
    "from fff.learning.util.messages import TorchMessage\n",
    "from fff.learning.gc.functions import eval_batch\n",
    "\n",
    "from torch_geometric.nn import data_parallel\n",
    "from torch_geometric.data import Batch\n",
    "## torch DDP, not completed\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "\n",
    "\n",
    "sch = GCSchNetForcefield()\n",
    "model = sch.get_model(StartModelMessage)\n",
    "\n",
    "model = data_parallel.DataParallel(model)\n",
    "model.to('cuda')\n",
    "\n",
    "# Unpack some inputs\n",
    "huber_eng, huber_force = huber_deltas\n",
    "batch_size: int = 32\n",
    "learning_rate: float = 1e-3\n",
    "huber_deltas: (float, float) = (0.5, 1)\n",
    "energy_weight: float = 0.1\n",
    "reset_weights: bool = False\n",
    "patience: int = None\n",
    "train_data = train_sets[0]\n",
    "valid_data = valid_sets[0]\n",
    "num_epochs = 32\n",
    "\n",
    "\n",
    "# Start the training process\n",
    "with TemporaryDirectory(prefix='spk') as td:\n",
    "    td = Path(td)\n",
    "    # Save the batch to an ASE Atoms database\n",
    "    with open(os.devnull, 'w') as fp, redirect_stderr(fp):\n",
    "        train_dataset = AtomsDataset.from_atoms(train_data, td / 'train')\n",
    "        # train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        train_loader = DataListLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        valid_dataset = AtomsDataset.from_atoms(valid_data, td / 'valid')\n",
    "        # valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "        valid_loader = DataListLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "    # Make the trainer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    if patience is None:\n",
    "        patience = num_epochs // 8\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=patience, factor=0.8, min_lr=1e-6)\n",
    "\n",
    "    # Store the best loss\n",
    "    best_loss = torch.inf\n",
    "\n",
    "    # Loop over epochs\n",
    "    log = []\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Iterate over all batches in the training set\n",
    "        train_losses = defaultdict(list)\n",
    "        for batch in train_loader:\n",
    "            # batch.to(device)\n",
    "            print(batch)\n",
    "            optimizer.zero_grad()\n",
    "            # energy, force = eval_batch(model, batch)\n",
    "            break\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data(x=[60], y=[1], pos=[60, 3], z=[60], f=[60, 3], n_atoms=[1], size=[1]), Data(x=[66], y=[1], pos=[66, 3], z=[66], f=[66, 3], n_atoms=[1], size=[1]), Data(x=[36], y=[1], pos=[36, 3], z=[36], f=[36, 3], n_atoms=[1], size=[1]), Data(x=[36], y=[1], pos=[36, 3], z=[36], f=[36, 3], n_atoms=[1], size=[1]), Data(x=[24], y=[1], pos=[24, 3], z=[24], f=[24, 3], n_atoms=[1], size=[1]), Data(x=[21], y=[1], pos=[21, 3], z=[21], f=[21, 3], n_atoms=[1], size=[1]), Data(x=[27], y=[1], pos=[27, 3], z=[27], f=[27, 3], n_atoms=[1], size=[1]), Data(x=[57], y=[1], pos=[57, 3], z=[57], f=[57, 3], n_atoms=[1], size=[1]), Data(x=[51], y=[1], pos=[51, 3], z=[51], f=[51, 3], n_atoms=[1], size=[1]), Data(x=[33], y=[1], pos=[33, 3], z=[33], f=[33, 3], n_atoms=[1], size=[1]), Data(x=[75], y=[1], pos=[75, 3], z=[75], f=[75, 3], n_atoms=[1], size=[1]), Data(x=[9], y=[1], pos=[9, 3], z=[9], f=[9, 3], n_atoms=[1], size=[1]), Data(x=[63], y=[1], pos=[63, 3], z=[63], f=[63, 3], n_atoms=[1], size=[1]), Data(x=[30], y=[1], pos=[30, 3], z=[30], f=[30, 3], n_atoms=[1], size=[1]), Data(x=[57], y=[1], pos=[57, 3], z=[57], f=[57, 3], n_atoms=[1], size=[1]), Data(x=[69], y=[1], pos=[69, 3], z=[69], f=[69, 3], n_atoms=[1], size=[1]), Data(x=[63], y=[1], pos=[63, 3], z=[63], f=[63, 3], n_atoms=[1], size=[1]), Data(x=[72], y=[1], pos=[72, 3], z=[72], f=[72, 3], n_atoms=[1], size=[1]), Data(x=[75], y=[1], pos=[75, 3], z=[75], f=[75, 3], n_atoms=[1], size=[1]), Data(x=[75], y=[1], pos=[75, 3], z=[75], f=[75, 3], n_atoms=[1], size=[1]), Data(x=[27], y=[1], pos=[27, 3], z=[27], f=[27, 3], n_atoms=[1], size=[1]), Data(x=[54], y=[1], pos=[54, 3], z=[54], f=[54, 3], n_atoms=[1], size=[1]), Data(x=[66], y=[1], pos=[66, 3], z=[66], f=[66, 3], n_atoms=[1], size=[1]), Data(x=[12], y=[1], pos=[12, 3], z=[12], f=[12, 3], n_atoms=[1], size=[1]), Data(x=[42], y=[1], pos=[42, 3], z=[42], f=[42, 3], n_atoms=[1], size=[1]), Data(x=[39], y=[1], pos=[39, 3], z=[39], f=[39, 3], n_atoms=[1], size=[1]), Data(x=[18], y=[1], pos=[18, 3], z=[18], f=[18, 3], n_atoms=[1], size=[1]), Data(x=[75], y=[1], pos=[75, 3], z=[75], f=[75, 3], n_atoms=[1], size=[1]), Data(x=[60], y=[1], pos=[60, 3], z=[60], f=[60, 3], n_atoms=[1], size=[1]), Data(x=[33], y=[1], pos=[33, 3], z=[33], f=[33, 3], n_atoms=[1], size=[1]), Data(x=[15], y=[1], pos=[15, 3], z=[15], f=[15, 3], n_atoms=[1], size=[1]), Data(x=[33], y=[1], pos=[33, 3], z=[33], f=[33, 3], n_atoms=[1], size=[1])]\n",
      "False\n",
      "DataBatch(x=[1473], y=[32], pos=[1473, 3], z=[1473], f=[1473, 3], n_atoms=[32], size=[32], batch=[1473], ptr=[33])\n",
      "<class 'list'>\n",
      "60\n",
      "torch.Size([1473, 3])\n",
      "True\n",
      "torch.Size([1473, 3])\n"
     ]
    }
   ],
   "source": [
    "## dataparallel\n",
    "\n",
    "print(batch)\n",
    "# energ_batch = model(batch)\n",
    "# print(energ_batch)\n",
    "\n",
    "\n",
    "batch_byBatch = Batch.from_data_list(batch)\n",
    "print(batch_byBatch.pos.requires_grad)\n",
    "print(batch_byBatch)\n",
    "batch_byBatch.pos.requires_grad = True\n",
    "print(type(batch))\n",
    "batch_pos= [i.pos for i in batch]\n",
    "for _ in batch_pos:\n",
    "    _.requires_grad = True\n",
    "print(len(batch_pos[:][0]))\n",
    "pos_tensor = torch.cat(batch_pos,dim=0).to('cuda')\n",
    "print(pos_tensor.size())\n",
    "print(pos_tensor.requires_grad)\n",
    "b_f = torch.cat([i.f for i in batch],dim=0)\n",
    "print(b_f.size())\n",
    "# force_batch = -torch.autograd.grad(energ_batch, batch.pos, grad_outputs=torch.ones_like(energ_batch), retain_graph=True)[0]\n",
    "# print(len(force_batch[:][-1]))\n",
    "# print(len(batch.pos[:][0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
