{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train task\n",
    "# train a model with enough runs\n",
    "# compare results with default MD DFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import logging\n",
    "import shutil\n",
    "from collections import deque\n",
    "from dataclasses import dataclass\n",
    "from random import shuffle, sample\n",
    "from typing import Dict, Any, Optional\n",
    "import json\n",
    "from functools import partial, update_wrapper\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import ase\n",
    "from ase.db import connect\n",
    "from ase.md.velocitydistribution import MaxwellBoltzmannDistribution\n",
    "from fff.learning.gc.ase import SchnetCalculator\n",
    "from fff.learning.gc.functions import GCSchNetForcefield\n",
    "from fff.learning.gc.models import SchNet, load_pretrained_model\n",
    "from fff.learning.util.messages import TorchMessage\n",
    "from fff.sampling.md import MolecularDynamics\n",
    "from fff.simulation import run_calculator, _run_calculator\n",
    "from fff.simulation.utils import read_from_string, write_to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/yxx/work/project/colmena/multisite_/my_test/training_task_test.ipynb Cell 3\u001b[0m line \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu_2/home/yxx/work/project/colmena/multisite_/my_test/training_task_test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m model_path \u001b[39m=\u001b[39m multisite_path \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/data/forcefields/starting-model/starting-model\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu_2/home/yxx/work/project/colmena/multisite_/my_test/training_task_test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m search_path \u001b[39m=\u001b[39m training_set\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu_2/home/yxx/work/project/colmena/multisite_/my_test/training_task_test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m out_dir \u001b[39m=\u001b[39m Path(multisite_path) \u001b[39m/\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmy_test/temp\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu_2/home/yxx/work/project/colmena/multisite_/my_test/training_task_test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m out_dir\u001b[39m.\u001b[39mmkdir(parents\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu_2/home/yxx/work/project/colmena/multisite_/my_test/training_task_test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m starting_model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(model_path, map_location\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "# path and varaibles\n",
    "multisite_path = \"/home/yxx/work/project/colmena/multisite_\"\n",
    "training_set = multisite_path + \\\n",
    "    \"/data/forcefields/starting-model/initial-database.db\"\n",
    "model_path = multisite_path + \"/data/forcefields/starting-model/starting-model\"\n",
    "search_path = training_set\n",
    "out_dir = Path(multisite_path) / f\"my_test/temp\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "starting_model = torch.load(model_path, map_location='cpu')\n",
    "\n",
    "num_epochs = 512\n",
    "huber_deltas = (1, 10)\n",
    "sampler_kwargs = {'device': \"cpu\", 'timestep': 0.1, 'log_interval': 10}\n",
    "sampler = MolecularDynamics()\n",
    "n_models = 1\n",
    "n_qc_workers = 8\n",
    "min_run_length = 200\n",
    "max_run_length = 2000\n",
    "energy_tolerance = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model pretreat\n",
    "\n",
    "# Apply wrappers to functions that will be used to fix certain requirements\n",
    "def _wrap(func, **kwargs):\n",
    "    out = partial(func, **kwargs)\n",
    "    update_wrapper(out, func)\n",
    "    return out\n",
    "\n",
    "# MD objectives\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Trajectory:\n",
    "    \"\"\"Tracks the state of searching along individual trajectories\n",
    "\n",
    "    We mark the starting point, the last point produced from sampling,\n",
    "    and the last point we produced that has been validated\n",
    "    \"\"\"\n",
    "    id: int  # ID number of the\n",
    "    starting: ase.Atoms  # Starting point of the trajectory\n",
    "    current_timestep = 0  # How many timesteps have been used so far\n",
    "    last_validated: ase.Atoms = None  # Last validated point on the trajectory\n",
    "    current: ase.Atoms = None  # Last point produced along the trajectory\n",
    "    last_run_length: int = 0  # How long between current and last_validated\n",
    "    name: str = None  # Name of the trajectory\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.last_validated = self.current = self.starting\n",
    "\n",
    "    def update_current_structure(self, strc: ase.Atoms, run_length: int):\n",
    "        \"\"\"Update the structure that has yet to be updated\n",
    "\n",
    "        Args:\n",
    "            strc: Structure produced by sampling\n",
    "            run_length: How many timesteps were performed in sampling run\n",
    "        \"\"\"\n",
    "        self.current = strc.copy()\n",
    "        self.last_run_length = run_length\n",
    "\n",
    "    def set_validation(self, success: bool):\n",
    "        \"\"\"Set whether the trajectory was successfully validated\n",
    "\n",
    "        Args:\n",
    "            success: Whether the validation was successful\n",
    "        \"\"\"\n",
    "        if success:\n",
    "            self.last_validated = self.current  # Move the last validated forward\n",
    "            self.current_timestep += self.last_run_length\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SimulationTask:\n",
    "    atoms: ase.Atoms  # Structure to be run\n",
    "    traj_id: int  # Which trajectory this came from\n",
    "    ml_eng: float  # Energy predicted from machine learning model\n",
    "    ml_std: Optional[float] = None  # Uncertainty of the model\n",
    "\n",
    "\n",
    "# get model\n",
    "schnet = GCSchNetForcefield(starting_model)\n",
    "\n",
    "# copy training data\n",
    "train_path = out_dir / \"train.db\"\n",
    "shutil.copyfile(training_set, train_path)\n",
    "\n",
    "# wrap functions\n",
    "# train model\n",
    "my_train_schnet = _wrap(schnet.train, num_epochs=num_epochs, device='cuda',\n",
    "                        patience=8, reset_weights=False,\n",
    "                        huber_deltas=huber_deltas)\n",
    "\n",
    "# evaluate model\n",
    "my_eval_schnet = _wrap(schnet.evaluate, device='cuda')\n",
    "\n",
    "# use model sampling\n",
    "my_run_dynamics = _wrap(sampler.run_sampling, **sampler_kwargs)\n",
    "\n",
    "\n",
    "# prepare input\n",
    "# Load in the search space\n",
    "with connect(search_path) as db:\n",
    "    search_space = [Trajectory(i, x.toatoms(), name=x.get(\n",
    "        'filename', f'traj-{i}')) for i, x in enumerate(db.select(''))]\n",
    "    shuffle(search_space)\n",
    "    search_space = deque(search_space)\n",
    "\n",
    "# Load in the training dataset\n",
    "with connect(train_path) as db:\n",
    "    all_examples = np.array([x.toatoms() for x in db.select(\"\")], dtype=object)\n",
    "\n",
    "    # Remove the unrealistic structures\n",
    "    # if self.max_force is not None:\n",
    "    #     all_examples = [a for a in all_examples if np.abs(a.get_forces()).max() < max_force]\n",
    "\n",
    "# search space queue\n",
    "to_audit: dict[int, Trajectory] = {}  # Trajectories that need to be audited\n",
    "audit_results: deque[float] = deque(maxlen=50)  # Results of the last 50 audits\n",
    "task_queue_audit = []\n",
    "\n",
    "# Prepare the initial model\n",
    "StartModelMessage = TorchMessage(starting_model)\n",
    "ActiveModelMessage = SchnetCalculator(starting_model)\n",
    "# Prepare the dataset\n",
    "train_sets = []\n",
    "valid_sets = []\n",
    "n_train = int(len(all_examples) * 0.9)\n",
    "for _ in range(n_models):\n",
    "    shuffle(all_examples)\n",
    "    train_sets.append(all_examples[:n_train])\n",
    "    valid_sets.append(all_examples[n_train:])\n",
    "\n",
    "# store model and log\n",
    "model_msgs = []\n",
    "train_logs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "for i in range(0, 1):\n",
    "    for i, train_set in enumerate(valid_sets):\n",
    "        model_msg, train_log = my_train_schnet(\n",
    "            model_msg=StartModelMessage, train_data=train_set, valid_data=valid_sets[i])\n",
    "        model_msgs.append(model_msg)\n",
    "        train_logs.append(train_log)\n",
    "\n",
    "    # store model\n",
    "    # now we just test one model\n",
    "    model_save_path = out_dir / \"model.pth\"\n",
    "    with open(model_save_path, 'wb') as fp:\n",
    "        torch.save(model_msgs[0].get_model(), fp)\n",
    "    # Save the training data\n",
    "    with open(out_dir / 'training-history.json', 'a') as fp:\n",
    "        print(json.dumps(train_logs[0].to_dict(orient='list')), file=fp)\n",
    "\n",
    "    active_model_proxy = SchnetCalculator(model_msgs[0].get_model())\n",
    "    StartModelMessage = TorchMessage(model_msgs[0].get_model())\n",
    "    model_msgs = []\n",
    "    train_logs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "Initialized temperature to 100K\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "# use model for sampling\n",
    "# sampling tasks loop\n",
    "for i in range(0, 100):\n",
    "    # Pick the next eligible trajectory and start from the last validated structure\n",
    "    trajectory = search_space.popleft()\n",
    "    starting_point = trajectory.starting\n",
    "\n",
    "    # Initialize the structure if need be\n",
    "    if trajectory.current_timestep == 0:\n",
    "        MaxwellBoltzmannDistribution(starting_point, temperature_K=100)\n",
    "        print('Initialized temperature to 100K')\n",
    "    # Add the structure to a list of those being validated\n",
    "    to_audit[trajectory.id] = trajectory\n",
    "\n",
    "    # Determine the run length based on observations of errors\n",
    "    run_length = min_run_length\n",
    "    if len(audit_results) > n_qc_workers:\n",
    "        # Predict run length given audit error\n",
    "        error_per_step = np.median(audit_results)\n",
    "        target_error = energy_tolerance * 2\n",
    "        estimated_run_length = int(target_error / error_per_step)\n",
    "        print(\n",
    "            f'Estimated run length of {estimated_run_length} steps to have an error of {target_error:.3f} eV/atom')\n",
    "        # Keep to within the user-defined bounds\n",
    "        run_length = max(min_run_length, min(\n",
    "            max_run_length, estimated_run_length))\n",
    "\n",
    "    # do sampling\n",
    "    audit, traj = my_run_dynamics(\n",
    "        atoms=starting_point, steps=run_length, calc=active_model_proxy)\n",
    "    # print(audit)\n",
    "    # print(len(traj))\n",
    "    # add to list\n",
    "    to_audit[trajectory.id].update_current_structure(audit, run_length)\n",
    "    task_queue_audit.append(SimulationTask(\n",
    "        atoms=traj[-1], traj_id=trajectory.id, ml_eng=traj[-1].get_potential_energy()))\n",
    "\n",
    "print(len(task_queue_audit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store sampling result\n",
    "import pickle\n",
    "with open(out_dir / 'task_queue_audit', 'wb') as fp:\n",
    "    pickle.dump(task_queue_audit, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Threads set to 24 by Python driver.\n",
      "  Threads set to 24 by Python driver.\n",
      "0.07407622481029345\n"
     ]
    }
   ],
   "source": [
    "# test simulation\n",
    "# real MD simulation\n",
    "tempdir = \"./temp\"\n",
    "\n",
    "# set calculator\n",
    "calc = dict(calc='psi4', method='pbe0-d3', basis='aug-cc-pvdz', num_threads=24)\n",
    "my_run_simulation = _wrap(run_calculator, calc=calc, temp_path=tempdir)\n",
    "\n",
    "# prepare input\n",
    "to_run = task_queue_audit[-1]\n",
    "ml_eng = to_run.ml_eng\n",
    "atoms = to_run.atoms\n",
    "atoms.set_center_of_mass([0, 0, 0])\n",
    "xyz = write_to_string(atoms, 'xyz')\n",
    "\n",
    "# run\n",
    "value = my_run_simulation(xyz)\n",
    "\n",
    "# result\n",
    "atoms = read_from_string(value, 'json')\n",
    "dft_energy = atoms.get_potential_energy()\n",
    "diff_energy = abs(dft_energy - ml_eng) / len(atoms)\n",
    "print(diff_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple grid search\n",
    "import time\n",
    "import itertools\n",
    "from ase.build import molecule\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from fff.simulation import run_calculator, _run_calculator\n",
    "from fff.simulation.utils import read_from_string, write_to_string\n",
    "\n",
    "parameter_space = []\n",
    "tempdir = \"./temp\"\n",
    "\n",
    "def generate_search_space(num_cpus, max_parallelism):\n",
    "    search_space = []\n",
    "    for parallelism in range(1, max_parallelism + 1):\n",
    "        combinations = itertools.combinations_with_replacement(\n",
    "            range(1, num_cpus + 1), parallelism)\n",
    "        for combination in combinations:\n",
    "            if sum(combination) == num_cpus:\n",
    "                search_space.append(combination)\n",
    "    return search_space\n",
    "\n",
    "\n",
    "def bundle_simulation_task(run_parames=[8, 8, 8], atoms_queue=[]):\n",
    "    # simulation here\n",
    "    atoms = []\n",
    "    task_infos = []\n",
    "    # for _ in range(0,len(run_parames)):\n",
    "    #     ##TODO we should choose proper atoms here\n",
    "    #     atoms.append(atoms_queue.pop())\n",
    "    \n",
    "    # simple test\n",
    "    # atoms.append(molecule('H2O'))\n",
    "    atoms = molecule('H2O')\n",
    "    with ProcessPoolExecutor(max_workers=len(run_parames)) as exe:\n",
    "        start_times = {}\n",
    "        futs = []\n",
    "        for i,cpus in enumerate(run_parames):\n",
    "            # atoms[0].set_center_of_mass([0, 0, 0])\n",
    "            xyz = write_to_string(atoms, 'xyz')\n",
    "            calc = dict(calc='psi4', method='pbe0-d3', basis='aug-cc-pvdz', num_threads=cpus)            \n",
    "            \n",
    "            fut = exe.submit(_run_calculator, str(xyz), calc, tempdir)\n",
    "            start_times[fut] = time.time()\n",
    "            futs.append(fut)\n",
    "            \n",
    "    execution_times = []\n",
    "    for fut in as_completed(futs):\n",
    "        execution_times.append(time.time() - start_times[fut])\n",
    "        calculated = read_from_string(fut.result(), 'json')\n",
    "        dft_energy = calculated.get_potential_energy()\n",
    "        # diff_energy = abs(dft_energy - ml_eng) / len(calculated)\n",
    "\n",
    "    # task_info = {\n",
    "    #     'atoms': calculated,\n",
    "    #     'run_parames': cpus,\n",
    "    #     'time': end - start,\n",
    "    #     #TODO 'ml_eng' : to_run.ml_eng,\n",
    "    #     'dft_eng': dft_energy,\n",
    "    # }\n",
    "    # task_infos.append(task_info)\n",
    "    return execution_times\n",
    "\n",
    "\n",
    "num_cpus = 24\n",
    "max_parallelism = 8\n",
    "parameter_space = generate_search_space(num_cpus, max_parallelism)\n",
    "\n",
    "print(len(parameter_space))\n",
    "print(parameter_space)\n",
    "\n",
    "gird_results = []\n",
    "for run_parames in parameter_space:\n",
    "    gird_results.append((run_parames,bundle_simulation_task(run_parames)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "821\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(len(gird_results))\n",
    "\n",
    "with open('./temp/grid_results.json', 'w') as json_file:\n",
    "    json.dump(gird_results, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Threads set to 24 by Python driver.\n",
      "  Threads set to 24 by Python driver.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Calculation failed: \nFatal Error: Matrix::power: C_DSYEV failed\nError occurred in file: /scratch/psilocaluser/conda-builds/psi4-multiout_1657298395608/work/psi4/src/psi4/libmints/matrix.cc on line: 2330\nThe most recent 5 function calls were:\n\npsi::FittingMetric::form_eig_inverse(double)\npsi::DiskDFJK::preiterations()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/yxx/work/project/colmena/multisite_/finetuning-surrogates/fff/simulation/__init__.py\", line 54, in _run_calculator\n    atoms.get_forces()\n  File \"/home/yxx/miniconda3/envs/multisite/lib/python3.9/site-packages/ase/atoms.py\", line 788, in get_forces\n    forces = self._calc.get_forces(self)\n  File \"/home/yxx/miniconda3/envs/multisite/lib/python3.9/site-packages/ase/calculators/abc.py\", line 23, in get_forces\n    return self.get_property('forces', atoms)\n  File \"/home/yxx/miniconda3/envs/multisite/lib/python3.9/site-packages/ase/calculators/calculator.py\", line 737, in get_property\n    self.calculate(atoms, [name], system_changes)\n  File \"/home/yxx/miniconda3/envs/multisite/lib/python3.9/site-packages/ase/calculators/psi4.py\", line 179, in calculate\n    grad, wf = self.psi4.driver.gradient('{}/{}'.format(method, basis),\n  File \"/home/yxx/miniconda3/envs/multisite/lib/python3.9/site-packages/psi4/driver/driver.py\", line 619, in gradient\n    wfn = procedures['gradient'][lowername](lowername, molecule=molecule, **kwargs)\n  File \"/home/yxx/miniconda3/envs/multisite/lib/python3.9/site-packages/psi4/driver/procrouting/proc.py\", line 90, in select_scf_gradient\n    return func(name, **kwargs)\n  File \"/home/yxx/miniconda3/envs/multisite/lib/python3.9/site-packages/psi4/driver/procrouting/proc.py\", line 2550, in run_scf_gradient\n    ref_wfn = run_scf(name, **kwargs)\n  File \"/home/yxx/miniconda3/envs/multisite/lib/python3.9/site-packages/psi4/driver/procrouting/proc.py\", line 2455, in run_scf\n    scf_wfn = scf_helper(name, post_scf=False, **kwargs)\n  File \"/home/yxx/miniconda3/envs/multisite/lib/python3.9/site-packages/psi4/driver/procrouting/proc.py\", line 1670, in scf_helper\n    e_scf = scf_wfn.compute_energy()\n  File \"/home/yxx/miniconda3/envs/multisite/lib/python3.9/site-packages/psi4/driver/procrouting/scf_proc/scf_iterator.py\", line 83, in scf_compute_energy\n    self.initialize()\n  File \"/home/yxx/miniconda3/envs/multisite/lib/python3.9/site-packages/psi4/driver/procrouting/scf_proc/scf_iterator.py\", line 193, in scf_initialize\n    self.initialize_jk(self.memory_jk_, jk=jk)\n  File \"/home/yxx/miniconda3/envs/multisite/lib/python3.9/site-packages/psi4/driver/procrouting/scf_proc/scf_iterator.py\", line 128, in initialize_jk\n    jk.initialize()\nRuntimeError: \nFatal Error: Matrix::power: C_DSYEV failed\nError occurred in file: /scratch/psilocaluser/conda-builds/psi4-multiout_1657298395608/work/psi4/src/psi4/libmints/matrix.cc on line: 2330\nThe most recent 5 function calls were:\n\npsi::FittingMetric::form_eig_inverse(double)\npsi::DiskDFJK::preiterations()\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/yxx/miniconda3/envs/multisite/lib/python3.9/concurrent/futures/process.py\", line 246, in _process_worker\n    r = call_item.fn(*call_item.args, **call_item.kwargs)\n  File \"/home/yxx/work/project/colmena/multisite_/finetuning-surrogates/fff/simulation/__init__.py\", line 57, in _run_calculator\n    raise ValueError(f'Calculation failed: {exc}')\nValueError: Calculation failed: \nFatal Error: Matrix::power: C_DSYEV failed\nError occurred in file: /scratch/psilocaluser/conda-builds/psi4-multiout_1657298395608/work/psi4/src/psi4/libmints/matrix.cc on line: 2330\nThe most recent 5 function calls were:\n\npsi::FittingMetric::form_eig_inverse(double)\npsi::DiskDFJK::preiterations()\n\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/yxx/work/project/colmena/multisite_/my_test/training_task_test.ipynb Cell 11\u001b[0m line \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu_2/home/yxx/work/project/colmena/multisite_/my_test/training_task_test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m xyz \u001b[39m=\u001b[39m write_to_string(atoms, \u001b[39m'\u001b[39m\u001b[39mxyz\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu_2/home/yxx/work/project/colmena/multisite_/my_test/training_task_test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m# run\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu_2/home/yxx/work/project/colmena/multisite_/my_test/training_task_test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m value \u001b[39m=\u001b[39m my_run_simulation(xyz)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu_2/home/yxx/work/project/colmena/multisite_/my_test/training_task_test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m# result\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu_2/home/yxx/work/project/colmena/multisite_/my_test/training_task_test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m atoms \u001b[39m=\u001b[39m read_from_string(value, \u001b[39m'\u001b[39m\u001b[39mjson\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/work/project/colmena/multisite_/finetuning-surrogates/fff/simulation/__init__.py:32\u001b[0m, in \u001b[0;36mrun_calculator\u001b[0;34m(xyz, calc, temp_path)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mwith\u001b[39;00m ProcessPoolExecutor(max_workers\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39mas\u001b[39;00m exe:\n\u001b[1;32m     31\u001b[0m     fut \u001b[39m=\u001b[39m exe\u001b[39m.\u001b[39msubmit(_run_calculator, \u001b[39mstr\u001b[39m(xyz), calc, temp_path)  \u001b[39m# str ensures proxies are resolved\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n",
      "File \u001b[0;32m~/miniconda3/envs/multisite/lib/python3.9/concurrent/futures/_base.py:446\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    445\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 446\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/miniconda3/envs/multisite/lib/python3.9/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Calculation failed: \nFatal Error: Matrix::power: C_DSYEV failed\nError occurred in file: /scratch/psilocaluser/conda-builds/psi4-multiout_1657298395608/work/psi4/src/psi4/libmints/matrix.cc on line: 2330\nThe most recent 5 function calls were:\n\npsi::FittingMetric::form_eig_inverse(double)\npsi::DiskDFJK::preiterations()\n"
     ]
    }
   ],
   "source": [
    "# test pickle serialization\n",
    "\n",
    "with open(out_dir / 'task_queue_audit', 'rb') as fp:\n",
    "    task_queue_audit_test = pickle.load(fp)\n",
    "\n",
    "# test simulation\n",
    "# real MD simulation\n",
    "tempdir = \"./temp\"\n",
    "\n",
    "# set calculator\n",
    "calc = dict(calc='psi4', method='pbe0-d3', basis='aug-cc-pvdz', num_threads=24)\n",
    "my_run_simulation = _wrap(run_calculator, calc=calc, temp_path=tempdir)\n",
    "\n",
    "# prepare input\n",
    "\n",
    "# to_run = task_queue_audit_test[-1]\n",
    "# ml_eng = to_run.ml_eng\n",
    "# atoms = to_run.atoms\n",
    "# atoms.set_center_of_mass([0, 0, 0])\n",
    "\n",
    "# atoms = molecule('H2O')\n",
    "# xyz = write_to_string(atoms, 'xyz')\n",
    "\n",
    "# run\n",
    "# value = my_run_simulation(xyz)\n",
    "\n",
    "# result\n",
    "# atoms = read_from_string(value, 'json')\n",
    "# dft_energy = atoms.get_potential_energy()\n",
    "# diff_energy = abs(dft_energy - ml_eng) / len(atoms)\n",
    "# print(diff_energy)\n",
    "\n",
    "\n",
    "execution_times = []\n",
    "diff_energies = []\n",
    "simulation_lists = []\n",
    "for to_run in task_queue_audit_test:\n",
    "    start = time.time()\n",
    "    ml_eng = to_run.ml_eng\n",
    "    atoms = to_run.atoms\n",
    "    atoms.set_center_of_mass([0, 0, 0])\n",
    "    xyz = write_to_string(atoms, 'xyz')\n",
    "\n",
    "    # run\n",
    "    value = my_run_simulation(xyz)\n",
    "    \n",
    "    # result\n",
    "    atoms = read_from_string(value, 'json')\n",
    "    dft_energy = atoms.get_potential_energy()\n",
    "    diff_energy = abs(dft_energy - ml_eng) / len(atoms)\n",
    "    diff_energies.append(diff_energy)\n",
    "    simulation_lists.append(atoms)\n",
    "    execution_times.append(time.time() - start)\n",
    "    # print(diff_energy)\n",
    "\n",
    "data = []\n",
    "for x,y,z in simulation_lists,diff_energies,execution_times:\n",
    "    data.append((x,y,z))\n",
    "with open('./temp/simulation_tasks_execution_time.json', 'w') as json_file:\n",
    "    json.dump(data, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ase\n",
    "import sys\n",
    "sys.path.append('../../multisite_')\n",
    "# sys.path.append('../my_util')\n",
    "from evt.evo_sch import *\n",
    "from my_util.data_structure import *\n",
    "from fff.simulation import run_calculator,_run_calculator\n",
    "from fff.simulation.utils import read_from_string, write_to_string\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
