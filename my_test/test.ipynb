{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "# 获取CPU核心数量\n",
    "num_cores = psutil.cpu_count(logical=False)\n",
    "\n",
    "# 循环获取每个CPU核的利用率\n",
    "for i in range(num_cores):\n",
    "    cpu_percent = psutil.cpu_percent(interval=1, percpu=True)\n",
    "    print(f\"CPU核心 {i+1} 的利用率: {cpu_percent[i]}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import os \n",
    "import subprocess\n",
    "cpu_list = [10,11,12,13]\n",
    "\n",
    "psutil.Process().cpu_affinity(cpu_list)\n",
    "process = subprocess.Popen(['python3','simple_test.py'])\n",
    "\n",
    "while process.poll() is None:\n",
    "    # cpu_percent = psutil.Process(process.pid).cpu_percent(interval=1)\n",
    "    cpu_percent = psutil.cpu_percent(interval=1,percpu=True)\n",
    "    for core,percent in enumerate(cpu_percent):\n",
    "        if core in cpu_list:\n",
    "            print(f\"核心{core}的利用率: {percent}%\")\n",
    "    print(f\"新程序在CPU上的利用率: {cpu_percent}%\")\n",
    "    \n",
    "    # 等待新程序运行结束\n",
    "process.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colmena.thinker import BaseThinker, result_processor, task_submitter, ResourceCounter\n",
    "from colmena.queue import PipeQueues\n",
    "from colmena.models import Result\n",
    "\n",
    "from colmena.task_server import ParslTaskServer\n",
    "from config import csecluster_RT_scale as make_config\n",
    "\n",
    "\"\"\"Example from the README\"\"\"\n",
    "\n",
    "##  Building the Thinker\n",
    "from random import random\n",
    "\n",
    "# Build queues to connect Thinker and Doer\n",
    "queues = PipeQueues()\n",
    "\n",
    "\n",
    "class Thinker(BaseThinker):\n",
    "\n",
    "    def __init__(self, queues, num_workers: int, num_guesses=100):\n",
    "        super().__init__(queues, ResourceCounter(num_workers))\n",
    "        self.best_result = None\n",
    "        self.answer = -10  # A (bad) starting guess\n",
    "        self.num_guesses = num_guesses\n",
    "\n",
    "    @task_submitter()\n",
    "    def submit_task(self):\n",
    "        \"\"\"Submit a new guess close to the current best whenever a node is free\"\"\"\n",
    "        self.queues.send_inputs(self.answer - 1 + 2 * random(), method='simulate')\n",
    "\n",
    "    @result_processor()\n",
    "    def store_result(self, result: Result):\n",
    "        \"\"\"Update best guess whenever a simulation finishes\"\"\"\n",
    "        assert result.success, result.failure_info\n",
    "        # Update the best result\n",
    "        if self.best_result is None or result.value > self.best_result:\n",
    "            self.answer = result.args[0]\n",
    "            self.best_result = result.value\n",
    "        self.rec.release()  # Mark that a node is now free\n",
    "\n",
    "        # Determine if we are done\n",
    "        self.num_guesses -= 1\n",
    "        if self.num_guesses <= 0:\n",
    "            self.done.set()\n",
    "\n",
    "\n",
    "thinker = Thinker(queues, 8)\n",
    "\n",
    "### Building the doer\n",
    "# from parsl.configs.htex_local import config  # Configuration to run locally\n",
    "from colmena.task_server import ParslTaskServer\n",
    "config = make_config(\"./\")\n",
    "\n",
    "\n",
    "# Define your function\n",
    "def simulate(x: float) -> float:\n",
    "    return - x ** 2 + 4\n",
    "\n",
    "\n",
    "# Make the Doer\n",
    "doer = ParslTaskServer([simulate], queues, config)\n",
    "\n",
    "# print(doer.config.executors)\n",
    "# gpu_executor = [executor for executor in doer.config.executors if executor.label == 'gpu'][0]\n",
    "# print(gpu_executor)\n",
    "a=doer.config.executors\n",
    "## Running the application\n",
    "# Launch the Thinker and doer\n",
    "# doer.start()\n",
    "# thinker.start()\n",
    "\n",
    "# # Wait until it finishes\n",
    "# thinker.join()\n",
    "# queues.send_kill_signal()\n",
    "\n",
    "# # Done!\n",
    "# print(f'Answer: f({thinker.answer:.2f}) = {thinker.best_result:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process_worker_pool.py debug 4 --available-accelerators [0, 1, 2, 3] \n",
      "process_worker_pool.py debug 4 --available-accelerators 1 \n"
     ]
    }
   ],
   "source": [
    "debug = \"debug\"\n",
    "max_workers = 4\n",
    "accelerators = [0,1,2,3]\n",
    "block_id = 1\n",
    "l_cmd = (\"process_worker_pool.py {debug} {max_workers} \"\n",
    "                               \"--available-accelerators {accelerators} \")\n",
    "cmd = l_cmd.format(debug=debug, max_workers=max_workers, accelerators = accelerators)\n",
    "print(cmd)\n",
    "l_cmd = l_cmd.replace(\"{accelerators}\", str(block_id))\n",
    "launch_cmd = l_cmd.format(debug=debug, max_workers=max_workers)\n",
    "print(launch_cmd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463bbc41-d4bf-44d5-8b37-d13f6fba739d\n",
      "44.38919379503932\n",
      "95.27356048696674\n",
      "106.35893604997545\n",
      "127.46185084490571\n",
      "210.88306554197334\n",
      "296.3696234700037\n",
      "390.35370990703814\n",
      "400.35233247396536\n",
      "454.6108865479473\n",
      "481.90589529590216\n",
      "486.8927287670085\n",
      "521.3457018379122\n",
      "537.9019012070494\n",
      "543.8459851499647\n",
      "610.6691218329361\n",
      "784.6231484480668\n",
      "1026.4671867439756\n",
      "1092.2011626909953\n",
      "1321.1727346020052\n",
      "1456.556674147956\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "file = Path('/home/lizz_lab/cse12232433/project/colmena/multisite_/finetuning-surrogates/runs/20230920_204954/dft-md-23Sep20-125003-d91b7e/simulation-results.json')\n",
    "\n",
    "tasks = []\n",
    "with open(file, 'r') as file:\n",
    "    # 逐行读取文件内容\n",
    "    for line in file:\n",
    "        # 解析 JSON 数据\n",
    "        task_info = []\n",
    "        data = json.loads(line)\n",
    "        task_info.append(data['task_id'])\n",
    "        task_info.append(data['task_info'])\n",
    "        task_info.append(data['time_running'])\n",
    "        tasks.append(task_info)\n",
    "\n",
    "print(data['task_id'])\n",
    "sorted_tasks = sorted(tasks, key=lambda x: x[2])\n",
    "for i in range(len(tasks)):\n",
    "    print(sorted_tasks[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list.append() takes exactly one argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/lizz_lab/cse12232433/project/colmena/multisite_/my_test/test.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225265736561726368265465616368696e67227d/home/lizz_lab/cse12232433/project/colmena/multisite_/my_test/test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(a))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225265736561726368265465616368696e67227d/home/lizz_lab/cse12232433/project/colmena/multisite_/my_test/test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m b \u001b[39m=\u001b[39m []\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a225265736561726368265465616368696e67227d/home/lizz_lab/cse12232433/project/colmena/multisite_/my_test/test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m b\u001b[39m.\u001b[39;49mappend(\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: list.append() takes exactly one argument (2 given)"
     ]
    }
   ],
   "source": [
    "a = {}\n",
    "print(type(a))\n",
    "b = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multisite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
