{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## gather simulation input, test following predict algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test Bsyesian optimization\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import catboost as cb\n",
    "from bayes_opt import BayesianOptimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class optimizationClass():\n",
    "    # 初始化的时候把数据集传进来\n",
    "    def __init__(self,df):\n",
    "        self.df = df \n",
    "        \n",
    "     # 定义一个评估指标的函数评估模型好坏   \n",
    "    def reg_calculate(self,true, prediction): \n",
    "        mse = metrics.mean_squared_error(true, prediction)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = metrics.mean_absolute_error(true, prediction)\n",
    "        mape = np.mean(np.abs((true - prediction) / true)) * 100\n",
    "        r2 = metrics.r2_score(true, prediction)\n",
    "        rmsle = np.sqrt(metrics.mean_squared_log_error(true, prediction))\n",
    "        # print(\"mse: {}, rmse: {}, mae: {}, mape: {}, r2: {}, rmsle: {}\".format(mse, rmse, mae, mape, r2, rmsle))\n",
    "        # return mse, rmse, mae, mape, r2, rmsle\n",
    "        return {\"mse\": mse, \"rmse\": rmse, \"mae\": mae, \"mape\": mape, \"r2\": r2, \"rmsle\": rmsle}    \n",
    "    \n",
    "    # 优化函数 参数为你需要调参的 hyper Parameter 这里用catBoost作为样例\n",
    "    def optimization_function(self,iterations,learning_rate,depth,l2_leaf_reg):\n",
    "        parameterDict = {\"iterations\":int(iterations),\"learning_rate\": float(learning_rate), \"depth\": int(depth),\n",
    "                         \"l2_leaf_reg\":float(l2_leaf_reg),\n",
    "                         \"task_type\":\"CPU\",\"logging_level\":\"Silent\"}\n",
    "        CB_Regressor=cb.CatBoostRegressor(**parameterDict)\n",
    "        CB_Regressor.fit(self.df[\"X_train\"], self.df[\"Y_train\"])\n",
    "        Y_pre=CB_Regressor.predict(self.df[\"X_test\"])\n",
    "        resDict =self.reg_calculate(self.df[\"Y_test\"],Y_pre)\n",
    "        return resDict[\"r2\"]\n",
    "    \n",
    "    # 定义一下模型\n",
    "    def run(self, init_points=2,n_iter=3):\n",
    "        cb_bo = BayesianOptimization(\n",
    "        self.optimization_function,\n",
    "        {'iterations': (200, 5000),\n",
    "        'learning_rate': (1e-6, 1e-2),\n",
    "        'depth': (2, 15),\n",
    "        'l2_leaf_reg': (0, 5)}\n",
    "        )\n",
    "        cb_bo.maximize(\n",
    "                        init_points=init_points,\n",
    "                        n_iter=n_iter)\n",
    "        print(\"Final result:\", cb_bo.max)\n",
    "#     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Opt = optimizationClass(df = {\"X_train\":X_Train, \"X_test\":X_Test, \"Y_train\":Y_Train, \"Y_test\":Y_Test})\n",
    "Opt.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'20240124_014903/dft-md-24Jan23-174907-4d97c4/simulation-results.json': '/home/lizz_lab/cse30019698/project/colmena/multisite_/finetuning-surrogates/analysis/runs/20240124_014903/dft-md-24Jan23-174907-4d97c4/simulation-results.json', '20240124_001447/dft-md-24Jan23-161451-5b14aa/simulation-results.json': '/home/lizz_lab/cse30019698/project/colmena/multisite_/finetuning-surrogates/analysis/runs/20240124_001447/dft-md-24Jan23-161451-5b14aa/simulation-results.json', '20240124_174540/dft-md-24Jan24-094544-8a6f62/simulation-results.json': '/home/lizz_lab/cse30019698/project/colmena/multisite_/finetuning-surrogates/analysis/runs/20240124_174540/dft-md-24Jan24-094544-8a6f62/simulation-results.json', '20240220_172152/dft-md-24Feb20-092155-f38847/simulation-results.json': '/home/lizz_lab/cse30019698/project/colmena/multisite_/finetuning-surrogates/analysis/runs/20240220_172152/dft-md-24Feb20-092155-f38847/simulation-results.json', '20240221_151441/dft-md-24Feb21-071447-e22b54/simulation-results.json': '/home/lizz_lab/cse30019698/project/colmena/multisite_/finetuning-surrogates/analysis/runs/20240221_151441/dft-md-24Feb21-071447-e22b54/simulation-results.json'}\n"
     ]
    }
   ],
   "source": [
    "# preprocess data\n",
    "from pathlib import Path\n",
    "import os\n",
    "path = Path('/home/lizz_lab/cse30019698/project/colmena/multisite_/finetuning-surrogates/analysis/runs')\n",
    "titles = ['sampling','simulation','training','inference']\n",
    "def find_files_with_title(directory, title):\n",
    "    result = {}\n",
    "    base_level = str(directory).count(os.sep)\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        if root.count(os.sep) <= base_level+3:  # 只遍历三级子目录\n",
    "            for file in files:\n",
    "                if title in file:\n",
    "                    relative_path = os.path.relpath(os.path.join(root, file), str(directory))\n",
    "                    result[relative_path] = os.path.join(root, file)\n",
    "    return result\n",
    "\n",
    "def get_running_metrics():\n",
    "    pass\n",
    "\n",
    "simulation_data = find_files_with_title(path, 'simulation')\n",
    "print(simulation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGBoost\n",
    "## test random forest\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 读取数据集\n",
    "data = pd.read_csv('task_runtimes.csv')\n",
    "\n",
    "# 提取特征和目标变量\n",
    "X = data.drop('runtime', axis=1)  # 特征\n",
    "y = data['runtime']  # 目标变量\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建随机森林回归模型\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# 评估模型性能\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"均方误差（MSE）: {mse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multisite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
