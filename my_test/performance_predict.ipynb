{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## gather simulation input, test following predict algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test Bsyesian optimization\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import catboost as cb\n",
    "from bayes_opt import BayesianOptimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class optimizationClass():\n",
    "    # 初始化的时候把数据集传进来\n",
    "    def __init__(self,df):\n",
    "        self.df = df \n",
    "        \n",
    "     # 定义一个评估指标的函数评估模型好坏   \n",
    "    def reg_calculate(self,true, prediction): \n",
    "        mse = metrics.mean_squared_error(true, prediction)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = metrics.mean_absolute_error(true, prediction)\n",
    "        mape = np.mean(np.abs((true - prediction) / true)) * 100\n",
    "        r2 = metrics.r2_score(true, prediction)\n",
    "        rmsle = np.sqrt(metrics.mean_squared_log_error(true, prediction))\n",
    "        # print(\"mse: {}, rmse: {}, mae: {}, mape: {}, r2: {}, rmsle: {}\".format(mse, rmse, mae, mape, r2, rmsle))\n",
    "        # return mse, rmse, mae, mape, r2, rmsle\n",
    "        return {\"mse\": mse, \"rmse\": rmse, \"mae\": mae, \"mape\": mape, \"r2\": r2, \"rmsle\": rmsle}    \n",
    "    \n",
    "    # 优化函数 参数为你需要调参的 hyper Parameter 这里用catBoost作为样例\n",
    "    def optimization_function(self,iterations,learning_rate,depth,l2_leaf_reg):\n",
    "        parameterDict = {\"iterations\":int(iterations),\"learning_rate\": float(learning_rate), \"depth\": int(depth),\n",
    "                         \"l2_leaf_reg\":float(l2_leaf_reg),\n",
    "                         \"task_type\":\"CPU\",\"logging_level\":\"Silent\"}\n",
    "        CB_Regressor=cb.CatBoostRegressor(**parameterDict)\n",
    "        CB_Regressor.fit(self.df[\"X_train\"], self.df[\"Y_train\"])\n",
    "        Y_pre=CB_Regressor.predict(self.df[\"X_test\"])\n",
    "        resDict =self.reg_calculate(self.df[\"Y_test\"],Y_pre)\n",
    "        return resDict[\"r2\"]\n",
    "    \n",
    "    # 定义一下模型\n",
    "    def run(self, init_points=2,n_iter=3):\n",
    "        cb_bo = BayesianOptimization(\n",
    "        self.optimization_function,\n",
    "        {'iterations': (200, 5000),\n",
    "        'learning_rate': (1e-6, 1e-2),\n",
    "        'depth': (2, 15),\n",
    "        'l2_leaf_reg': (0, 5)}\n",
    "        )\n",
    "        cb_bo.maximize(\n",
    "                        init_points=init_points,\n",
    "                        n_iter=n_iter)\n",
    "        print(\"Final result:\", cb_bo.max)\n",
    "#     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Opt = optimizationClass(df = {\"X_train\":X_Train, \"X_test\":X_Test, \"Y_train\":Y_Train, \"Y_test\":Y_Test})\n",
    "Opt.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colmena.models import Result\n",
    "\n",
    "result_list = []\n",
    "result = Result(\n",
    "    (('name',), {'a':1}),\n",
    "    method=\"method\",\n",
    "    keep_inputs=True,\n",
    "    task_info={\"resources\": {\"num_cpus\": 1, \"num_gpus\": 0}},\n",
    "    resources={\"num_cpus\": 2, \"num_gpus\": 0, \"num_threads\": 2}\n",
    ")\n",
    "result_list.append(result)\n",
    "result = Result(\n",
    "    (('name',), {'a':1}),\n",
    "    method=\"method\",\n",
    "    keep_inputs=True,\n",
    "    task_info={\"resources\": {\"num_cpus\": 1, \"num_gpus\": 0}},\n",
    "    resources={\"num_cpus\": 4, \"num_gpus\": 0, \"num_threads\": 2}\n",
    ")\n",
    "result_list.append(result)\n",
    "\n",
    "features = [\n",
    "    'resources,num_cpus',\n",
    "    'resources,num_gpus',\n",
    "    'resources,num_threads'\n",
    "]\n",
    "data = []\n",
    "feature_values = {}\n",
    "for result in result_list:\n",
    "    for feature in features:\n",
    "        feature = feature.split(',')\n",
    "        for i in range(len(feature)):\n",
    "            value = getattr(result, feature[i], None)\n",
    "        feature_values[feature[-1]] = value\n",
    "    data.append(feature_values)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "# preprocess data\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "# path = Path('/home/lizz_lab/cse30019698/project/colmena/multisite_/finetuning-surrogates/analysis/runs')\n",
    "# wsl local path \n",
    "path = Path('/home/lizz_lab/cse30019698/project/colmena/multisite_/finetuning-surrogates/analysis/runs/20240227_192900')\n",
    "titles = ['sampling','simulation','training','inference']\n",
    "def find_files_with_title(directory, title):\n",
    "    result = {}\n",
    "    base_level = str(directory).count(os.sep)\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        if root.count(os.sep) <= base_level+3:  # 只遍历三级子目录\n",
    "            for file in files:\n",
    "                if title in file:\n",
    "                    relative_path = os.path.relpath(os.path.join(root, file), str(directory))\n",
    "                    result[relative_path] = os.path.join(root, file)\n",
    "    return result\n",
    "\n",
    "features = [\n",
    "    # \"method\",\n",
    "    \"message_sizes.inputs\",\n",
    "    # \"worker_info.hostname\",\n",
    "    \"resources.node_count\",\n",
    "    \"resources.cpu_processes\",\n",
    "    \"resources.cpu_threads\",\n",
    "    \"time_running\"]\n",
    "        \n",
    "def get_running_metrics(data_path,features):\n",
    "    data = []\n",
    "    for path in data_path:\n",
    "        with open(path) as f:\n",
    "            for line in f:\n",
    "                log = json.loads(line)\n",
    "                feature_values = {}\n",
    "                for feature in features:\n",
    "                    feature_value = log\n",
    "                    for key in feature.split(\".\"):\n",
    "                        feature_value = feature_value.get(key)\n",
    "                        if feature_value is None:\n",
    "                            break\n",
    "                    feature_values[feature] = feature_value\n",
    "                data.append(feature_values)\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "simulation_data = find_files_with_title(path, 'simulation')\n",
    "print(simulation_data)\n",
    "df = get_running_metrics(simulation_data.values(),features)\n",
    "# label_encoder = LabelEncoder()\n",
    "# encoded_labels = label_encoder.fit_transform(df['method'])\n",
    "# df['method'] = encoded_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   message_sizes.inputs  resources.node_count resources.cpu_processes  \\\n",
      "0                  8733                     1                      16   \n",
      "1                  7869                     1                      16   \n",
      "2                  7869                     1                      16   \n",
      "3                  1387                     1                      16   \n",
      "4                  3549                     1                      16   \n",
      "\n",
      "   resources.cpu_threads  time_running  \n",
      "0                      1    450.060844  \n",
      "1                      1    152.374982  \n",
      "2                      1    191.483258  \n",
      "3                      1      4.547907  \n",
      "4                      1     33.308450  \n",
      "(176, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测值: 68.22887702589544, 实际值: 64.45904402434826\n",
      "预测值: 29.902914699492417, 实际值: 31.66200151713565\n",
      "预测值: 207.94587903871346, 实际值: 218.76287353923544\n",
      "预测值: 128.86375018477466, 实际值: 118.2591360528022\n",
      "预测值: 71.78310965596246, 实际值: 75.06399099109694\n",
      "预测值: 123.49271703878678, 实际值: 93.18448483897373\n",
      "预测值: 2912.0254765669483, 实际值: 3033.612930558156\n",
      "预测值: 109.40814889019356, 实际值: 130.4530840329826\n",
      "预测值: 15.71897856842272, 实际值: 16.42160639585927\n",
      "预测值: 444.73675419209235, 实际值: 531.904815223068\n",
      "预测值: 333.1232807943023, 实际值: 315.3497639307752\n",
      "预测值: 53.837410173350946, 实际值: 59.992288656998426\n",
      "预测值: 634.306247070415, 实际值: 559.8373141619377\n",
      "预测值: 287.53674668864693, 实际值: 323.5934388479218\n",
      "预测值: 246.6296064982663, 实际值: 229.7090552840382\n",
      "预测值: 75.78134263334873, 实际值: 88.68210051394999\n",
      "预测值: 91.21208394491114, 实际值: 106.03658497519791\n",
      "预测值: 102.85138550474866, 实际值: 111.69201503833756\n",
      "预测值: 52.58134820472573, 实际值: 69.93717657169327\n",
      "预测值: 371.294023298903, 实际值: 455.9879334741272\n",
      "预测值: 158.39513198443657, 实际值: 162.2259537470527\n",
      "预测值: 148.6914960767665, 实际值: 130.3563524163328\n",
      "预测值: 299.32097274810604, 实际值: 282.974710281007\n",
      "预测值: 145.96539434099066, 实际值: 92.21742171281949\n",
      "预测值: 456.85759815819404, 实际值: 613.6098909210414\n",
      "预测值: 822.2376501028942, 实际值: 890.8763922760263\n",
      "预测值: 89.61246951702051, 实际值: 60.327351200859994\n",
      "预测值: 52.58134820472573, 实际值: 59.46210752101615\n",
      "预测值: 30.174205835573826, 实际值: 45.05275317141786\n",
      "预测值: 122.98986603610588, 实际值: 90.45868671918288\n",
      "预测值: 145.96539434099066, 实际值: 95.56227441877127\n",
      "预测值: 146.98783993113778, 实际值: 178.70999810378999\n",
      "预测值: 6.284321234631817, 实际值: 4.947270527947694\n",
      "预测值: 444.73675419209235, 实际值: 462.3157349880785\n",
      "预测值: 230.03535248596782, 实际值: 231.72113192500547\n",
      "均方误差（MSE）: 2236.0057854651304\n"
     ]
    }
   ],
   "source": [
    "## test random forest\n",
    "data = df.apply(pd.to_numeric, errors='coerce')\n",
    "data = data.dropna()  # 删除缺失值\n",
    "# 提取特征和目标变量\n",
    "X = data.drop('time_running', axis=1)  # 特征\n",
    "y = data['time_running']  # 目标变量\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建随机森林回归模型\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    print(f\"预测值: {y_pred[i]}, 实际值: {y_test.iloc[i]}\")\n",
    "\n",
    "\n",
    "# 评估模型性能\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"均方误差（MSE）: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测值: 66.5465087890625, 实际值: 64.45904402434826\n",
      "预测值: 31.840682983398438, 实际值: 31.66200151713565\n",
      "预测值: 206.184326171875, 实际值: 218.76287353923544\n",
      "预测值: 139.84230041503906, 实际值: 118.2591360528022\n",
      "预测值: 71.81390380859375, 实际值: 75.06399099109694\n",
      "预测值: 129.35867309570312, 实际值: 93.18448483897373\n",
      "预测值: 3017.46826171875, 实际值: 3033.612930558156\n",
      "预测值: 113.20099639892578, 实际值: 130.4530840329826\n",
      "预测值: 15.658439636230469, 实际值: 16.42160639585927\n",
      "预测值: 457.42498779296875, 实际值: 531.904815223068\n",
      "预测值: 323.9720153808594, 实际值: 315.3497639307752\n",
      "预测值: 79.36309814453125, 实际值: 59.992288656998426\n",
      "预测值: 565.822265625, 实际值: 559.8373141619377\n",
      "预测值: 301.04541015625, 实际值: 323.5934388479218\n",
      "预测值: 236.3675994873047, 实际值: 229.7090552840382\n",
      "预测值: 80.52764892578125, 实际值: 88.68210051394999\n",
      "预测值: 62.70760726928711, 实际值: 106.03658497519791\n",
      "预测值: 97.02880859375, 实际值: 111.69201503833756\n",
      "预测值: 63.95719528198242, 实际值: 69.93717657169327\n",
      "预测值: 337.2482604980469, 实际值: 455.9879334741272\n",
      "预测值: 167.89044189453125, 实际值: 162.2259537470527\n",
      "预测值: 157.20904541015625, 实际值: 130.3563524163328\n",
      "预测值: 234.99139404296875, 实际值: 282.974710281007\n",
      "预测值: 117.34486389160156, 实际值: 92.21742171281949\n",
      "预测值: 443.8003234863281, 实际值: 613.6098909210414\n",
      "预测值: 818.5042724609375, 实际值: 890.8763922760263\n",
      "预测值: 62.70760726928711, 实际值: 60.327351200859994\n",
      "预测值: 63.95719528198242, 实际值: 59.46210752101615\n",
      "预测值: 31.50051498413086, 实际值: 45.05275317141786\n",
      "预测值: 121.20018768310547, 实际值: 90.45868671918288\n",
      "预测值: 117.34486389160156, 实际值: 95.56227441877127\n",
      "预测值: 155.63040161132812, 实际值: 178.70999810378999\n",
      "预测值: 5.606919765472412, 实际值: 4.947270527947694\n",
      "预测值: 457.42498779296875, 实际值: 462.3157349880785\n",
      "预测值: 233.89071655273438, 实际值: 231.72113192500547\n",
      "均方误差（MSE）: 1866.7526806740502\n"
     ]
    }
   ],
   "source": [
    "# test xgboost\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "data = df.apply(pd.to_numeric, errors='coerce')\n",
    "data = data.dropna()  # 删除缺失值\n",
    "# 提取特征和目标变量\n",
    "X = data.drop('time_running', axis=1)  # 特征\n",
    "y = data['time_running']  # 目标变量\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建XGBoost回归模型\n",
    "xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# 逐行打印预测值和实际值进行比较\n",
    "for i in range(len(y_pred)):\n",
    "    print(f\"预测值: {y_pred[i]}, 实际值: {y_test.iloc[i]}\")\n",
    "\n",
    "# 评估模型性能\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"均方误差（MSE）: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "results = []\n",
    "# 读取 JSON 文件\n",
    "with open('/home/lizz_lab/cse30019698/project/colmena/multisite_/finetuning-surrogates/runs/20240227_012918/dft-md-24Feb26-213555-1434fe/simulation-results.json', 'r') as f:\n",
    "\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        # print(data)\n",
    "        # 修改每一行的 \"cpu_processes\"\n",
    "        data['resources']['cpu_processes'] = '1'\n",
    "        results.append(data)\n",
    "        # 将修改后的数据写回 JSON 文件\n",
    "with open('/home/lizz_lab/cse30019698/project/colmena/multisite_/finetuning-surrogates/runs/20240227_012918/simulation-results_1.json', 'w') as f:\n",
    "    for data in results:\n",
    "        json.dump(data, f)\n",
    "        f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multisite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
