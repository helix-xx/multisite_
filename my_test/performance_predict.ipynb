{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test Bsyesian optimization\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import catboost as cb\n",
    "from bayes_opt import BayesianOptimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class optimizationClass():\n",
    "    # 初始化的时候把数据集传进来\n",
    "    def __init__(self,df):\n",
    "        self.df = df \n",
    "        \n",
    "     # 定义一个评估指标的函数评估模型好坏   \n",
    "    def reg_calculate(self,true, prediction): \n",
    "        mse = metrics.mean_squared_error(true, prediction)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = metrics.mean_absolute_error(true, prediction)\n",
    "        mape = np.mean(np.abs((true - prediction) / true)) * 100\n",
    "        r2 = metrics.r2_score(true, prediction)\n",
    "        rmsle = np.sqrt(metrics.mean_squared_log_error(true, prediction))\n",
    "        # print(\"mse: {}, rmse: {}, mae: {}, mape: {}, r2: {}, rmsle: {}\".format(mse, rmse, mae, mape, r2, rmsle))\n",
    "        # return mse, rmse, mae, mape, r2, rmsle\n",
    "        return {\"mse\": mse, \"rmse\": rmse, \"mae\": mae, \"mape\": mape, \"r2\": r2, \"rmsle\": rmsle}    \n",
    "    \n",
    "    # 优化函数 参数为你需要调参的 hyper Parameter 这里用catBoost作为样例\n",
    "    def optimization_function(self,iterations,learning_rate,depth,l2_leaf_reg):\n",
    "        parameterDict = {\"iterations\":int(iterations),\"learning_rate\": float(learning_rate), \"depth\": int(depth),\n",
    "                         \"l2_leaf_reg\":float(l2_leaf_reg),\n",
    "                         \"task_type\":\"CPU\",\"logging_level\":\"Silent\"}\n",
    "        CB_Regressor=cb.CatBoostRegressor(**parameterDict)\n",
    "        CB_Regressor.fit(self.df[\"X_train\"], self.df[\"Y_train\"])\n",
    "        Y_pre=CB_Regressor.predict(self.df[\"X_test\"])\n",
    "        resDict =self.reg_calculate(self.df[\"Y_test\"],Y_pre)\n",
    "        return resDict[\"r2\"]\n",
    "    \n",
    "    # 定义一下模型\n",
    "    def run(self, init_points=2,n_iter=3):\n",
    "        cb_bo = BayesianOptimization(\n",
    "        self.optimization_function,\n",
    "        {'iterations': (200, 5000),\n",
    "        'learning_rate': (1e-6, 1e-2),\n",
    "        'depth': (2, 15),\n",
    "        'l2_leaf_reg': (0, 5)}\n",
    "        )\n",
    "        cb_bo.maximize(\n",
    "                        init_points=init_points,\n",
    "                        n_iter=n_iter)\n",
    "        print(\"Final result:\", cb_bo.max)\n",
    "#     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Opt = optimizationClass(df = {\"X_train\":X_Train, \"X_test\":X_Test, \"Y_train\":Y_Train, \"Y_test\":Y_Test})\n",
    "Opt.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGBoost\n",
    "## test random forest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multisite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
